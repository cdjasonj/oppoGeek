{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start_run_feature\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "14\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "15\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "16\n",
      "17\n",
      "17\n",
      "17\n",
      "17\n",
      "18\n",
      "18\n",
      "18\n",
      "19\n",
      "19\n",
      "20\n",
      "part2_finish\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-0d2e8a1e214d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'start_run_feature'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 632\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_feature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    633\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'feature_del'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mco_feature_del\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-0d2e8a1e214d>\u001b[0m in \u001b[0;36mrun_feature\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    421\u001b[0m         \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'flag'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m         \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mas_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'_click_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     60\u001b[0m                          \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindicator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindicator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                          validate=validate)\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/reshape/merge.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    580\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mldata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlindexers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrindexers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             \u001b[0maxes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mllabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoin_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 582\u001b[0;31m             concat_axis=0, copy=self.copy)\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mtyp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconcatenate_block_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m   5419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5420\u001b[0m             b = make_block(\n\u001b[0;32m-> 5421\u001b[0;31m                 \u001b[0mconcatenate_join_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5422\u001b[0m                 placement=placement)\n\u001b[1;32m   5423\u001b[0m         \u001b[0mblocks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mconcatenate_join_units\u001b[0;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[1;32m   5563\u001b[0m     to_concat = [ju.get_reindexed_values(empty_dtype=empty_dtype,\n\u001b[1;32m   5564\u001b[0m                                          upcasted_na=upcasted_na)\n\u001b[0;32m-> 5565\u001b[0;31m                  for ju in join_units]\n\u001b[0m\u001b[1;32m   5566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5567\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   5563\u001b[0m     to_concat = [ju.get_reindexed_values(empty_dtype=empty_dtype,\n\u001b[1;32m   5564\u001b[0m                                          upcasted_na=upcasted_na)\n\u001b[0;32m-> 5565\u001b[0;31m                  for ju in join_units]\n\u001b[0m\u001b[1;32m   5566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5567\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_concat\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/internals.py\u001b[0m in \u001b[0;36mget_reindexed_values\u001b[0;34m(self, empty_dtype, upcasted_na)\u001b[0m\n\u001b[1;32m   5873\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5874\u001b[0m                 values = algos.take_nd(values, indexer, axis=ax,\n\u001b[0;32m-> 5875\u001b[0;31m                                        fill_value=fill_value)\n\u001b[0m\u001b[1;32m   5876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5877\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/algorithms.py\u001b[0m in \u001b[0;36mtake_nd\u001b[0;34m(arr, indexer, axis, out, fill_value, mask_info, allow_fill)\u001b[0m\n\u001b[1;32m   1650\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'F'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1651\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1652\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1654\u001b[0m     func = _get_take_nd_function(arr.ndim, arr.dtype, out.dtype, axis=axis,\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import Levenshtein\n",
    "from gensim import matutils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import warnings\n",
    "import os\n",
    "import jieba\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from operator import itemgetter\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold as skf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from sklearn.metrics import f1_score\n",
    "import gc\n",
    "\n",
    "def get_data():\n",
    "    if mode == \"test\":\n",
    "        train = pd.read_table('/home/ccit/tkhoon/data/sdata_train.csv', header=None,\n",
    "                              names=['prefix', 'query_prediction', 'title', 'tag', 'label', '1'], quoting=3)\n",
    "        vali = pd.read_table('/home/ccit/tkhoon/data/sdata_vali.csv', header=None, names=['prefix', 'query_prediction', 'title', 'tag', 'label'],\n",
    "                             quoting=3)\n",
    "        test = pd.read_table('/home/ccit/tkhoon/data/sdata_test.csv', header=None, names=['prefix', 'query_prediction', 'title', 'tag', '1'],\n",
    "                             quoting=3)\n",
    "    else:\n",
    "        train = pd.read_table('/home/ccit/tkhoon/data/data_train.csv', header=None,\n",
    "                              names=['prefix', 'query_prediction', 'title', 'tag', 'label', '1'], quoting=3)\n",
    "        vali = pd.read_table('/home/ccit/tkhoon/data/data_vali.csv', header=None, names=['prefix', 'query_prediction', 'title', 'tag', 'label'],\n",
    "                             quoting=3)\n",
    "        test = pd.read_table('/home/ccit/tkhoon/data/data_test.csv', header=None, names=['prefix', 'query_prediction', 'title', 'tag', '1'],\n",
    "                             quoting=3)\n",
    "\n",
    "\n",
    "    train_temp = train[train['1'].notnull()]\n",
    "    test_temp = test[test['1'].notnull()]\n",
    "\n",
    "    train_index = list(train_temp.index)\n",
    "    test_index = list(test_temp.index)\n",
    "\n",
    "    train.loc[train_index, 'tag'] = train.loc[train_index, 'label']\n",
    "    train.loc[train_index, 'label'] = train.loc[train_index, '1']\n",
    "\n",
    "    test.loc[test_index, 'tag'] = test.loc[test_index, '1']\n",
    "\n",
    "    train.drop('1', axis=1, inplace=True)\n",
    "    test.drop('1', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    test['label'] = -1\n",
    "    train['flag'] = 1\n",
    "    vali['flag'] = 2\n",
    "    test['flag'] = 3\n",
    "    data = pd.concat([train, vali, test])\n",
    "    data = data.reset_index()\n",
    "    data.drop('index', axis=1, inplace=True)\n",
    "\n",
    "    columns = ['prefix', 'query_prediction', 'title', 'tag']\n",
    "    for column in columns:\n",
    "        data[column] = data[column].astype(str)\n",
    "    data.drop( data[ data[\"label\"].isnull() ].index , inplace=True )\n",
    "    data['label'] = data['label'].astype(int)\n",
    "    return data\n",
    "\n",
    "def char_process(char):\n",
    "    # 提出无效字符\n",
    "    try:\n",
    "        char =  re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+??！，。？?、~@#￥%……&*（）:]+\", \"\", char)\n",
    "        return char\n",
    "    except:\n",
    "        return char\n",
    "\n",
    "def is_prefix_contains_upper_english(data):\n",
    "    judge = data['prefix'].apply(lambda x: len(re.findall(\"[A-Z]\", x)) > 0 )\n",
    "    # data[judge]\n",
    "    data['is_prefix_contains_upper_english'] = 0\n",
    "    data.loc[judge, 'is_prefix_contains_upper_english'] = 1\n",
    "    return data\n",
    "\n",
    "def char_lowwer_process(item):\n",
    "        if (item['is_prefix_contains_upper_english'] == 1) & (item['query_prediction'] == 'nan'):\n",
    "            return str.lower(item['prefix'])\n",
    "        else :\n",
    "            return item['prefix']\n",
    "\n",
    "def title_char_lowwer_process(item):\n",
    "        if (item['is_prefix_contains_upper_english'] == 1) & (item['query_prediction'] == 'nan'):\n",
    "            return str.lower(item['title'])\n",
    "        else :\n",
    "            return item['title']\n",
    "\n",
    "def char_cleaner(char):\n",
    "    if not isinstance(char, str):\n",
    "        char = \"null\"\n",
    "    pattern = re.compile(\"[^0-9a-zA-Z\\u4E00-\\u9FA5 ]\")\n",
    "    char = re.sub(pattern, \"\", char)\n",
    "    char = char.lower()\n",
    "    return char\n",
    "\n",
    "def is_prefix_contains_upper_english(data):\n",
    "    judge = data['prefix'].apply(lambda x: len(re.findall(\"[A-Z]\", x)) > 0 )\n",
    "    # data[judge]\n",
    "    data['is_prefix_contains_upper_english'] = 0\n",
    "    data.loc[judge, 'is_prefix_contains_upper_english'] = 1\n",
    "    return data\n",
    "\n",
    "def query_process(item):\n",
    "    try:\n",
    "        item['query_prediction'] = json.loads(item['query_prediction'])\n",
    "        return item['query_prediction']\n",
    "    except:\n",
    "        return '{}'\n",
    "\n",
    "def combine_tag(item):\n",
    "    if item['tag'] == '网页':\n",
    "        return '网站'\n",
    "    else:\n",
    "        return item['tag']\n",
    "complete_prefix_map={}\n",
    "def get_complete_prefix(item):\n",
    "        prefix = item['prefix']\n",
    "        complete_prefix = complete_prefix_map.get(prefix  )\n",
    "        if complete_prefix is not None:\n",
    "            return  complete_prefix\n",
    "        query_prediction = item['query_prediction']\n",
    "\n",
    "        if query_prediction == '{}':\n",
    "            return prefix\n",
    "\n",
    "        predict_word_dict = dict()\n",
    "        prefix = str(prefix)\n",
    "\n",
    "        for query_item, query_ratio in query_prediction.items():\n",
    "            query_item_cut = jieba.lcut(query_item)\n",
    "            item_word = \"\"\n",
    "            for item in query_item_cut:\n",
    "                if prefix not in item_word:\n",
    "                    item_word += item\n",
    "                else:\n",
    "                    if item_word not in predict_word_dict.keys():\n",
    "                        predict_word_dict[item_word] = 0.0\n",
    "                    predict_word_dict[item_word] += float(query_ratio)\n",
    "\n",
    "        if not predict_word_dict:\n",
    "            return prefix\n",
    "\n",
    "        predict_word_dict = sorted(predict_word_dict.items(), key=itemgetter(1), reverse=True)\n",
    "        complete_prefix = predict_word_dict[0][0]\n",
    "        complete_prefix_map[ prefix ] = complete_prefix\n",
    "        return complete_prefix\n",
    "\n",
    "def run_process(data):\n",
    "\n",
    "    data['prefix'] = data['prefix'].apply(char_process) #提出无效字符j\n",
    "    data['title'] = data['title'].apply(char_process) #title也去掉，之后涉及到计算相似度问题\n",
    "    data  = is_prefix_contains_upper_english(data) #判断prefix是否含有大写\n",
    "    data['prefix'] = data.apply(char_lowwer_process,axis=1) #将含有大写的prefix转为小写    有转化成小写的 ,query一定为空\n",
    "    data['title'] = data.apply(title_char_lowwer_process,axis=1)#把title也转换成小写\n",
    "    data['tag'] = data.apply(combine_tag,axis=1) #合并tag\n",
    "    return data\n",
    "\n",
    "def get_prefix_query_dic(data):\n",
    "    prefix_dic = {}\n",
    "    for index,row in data.iterrows():\n",
    "        if row['query_prediction'] != 'nan' and row['prefix'] not in prefix_dic:\n",
    "            prefix_dic[row['prefix']] = row['query_prediction']\n",
    "    return prefix_dic\n",
    "\n",
    "def null_query_prediction_process(item):\n",
    "    if item['query_prediction'] == 'nan' and item['prefix'] in prefix_dic:\n",
    "        return prefix_dic[item['prefix']]\n",
    "    else:\n",
    "        return item['query_prediction']\n",
    "\n",
    "def move_useless_char(s):\n",
    "    # 提出无效字符\n",
    "    return re.sub(\"[\\s+\\.\\!\\/_,$%^*(+\\\"\\']+|[+??！，。？?、~@#￥%……&*（）:]+\", \"\", s)\n",
    "\n",
    "def query_prediction_text(query_prediction):\n",
    "    if query_prediction == '{}':\n",
    "        return ['PAD'];\n",
    "    else:\n",
    "        query_word = []\n",
    "        for i in query_prediction.keys():\n",
    "            query_word.append(i)\n",
    "    #移除query_word无效字符\n",
    "    for i in range(len(query_word)):\n",
    "        query_word[i] = move_useless_char(query_word[i])\n",
    "    return query_word\n",
    "\n",
    "def query_prediction_score(query_prediction):\n",
    "    if query_prediction == '{}':\n",
    "        return np.nan\n",
    "    else:\n",
    "        query_score = []\n",
    "        for i in query_prediction.values():\n",
    "            query_score.append(float(i))\n",
    "    return query_score\n",
    "\n",
    "def get_query_list_feature(data):\n",
    "    data['query_word'] = data['query_prediction'].apply(lambda x : query_prediction_text(x))\n",
    "    data['query_score'] = data['query_prediction'].apply(lambda x: query_prediction_score(x))\n",
    "    return data\n",
    "\n",
    "def get_word_length(item):\n",
    "    word_cut = jieba.lcut(item)\n",
    "    return len(word_cut)\n",
    "\n",
    "def title_is_in_query(item):\n",
    "    if item['query_prediction'] == '{}' or item['title'] not in item['query_word']:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def prefix_is_in_title(item):\n",
    "    if item['prefix'] == 'nan' or item['title'] == 'nan' or item['prefix'] not in item['title']:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "def prefix_is_network(item):\n",
    "    if 'www' in item or 'com' in item or 'http' in item:\n",
    "        return 1\n",
    "\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def title_is_network(item):\n",
    "    if 'www' in item or 'com' in item or 'http' in item:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def prefix_is_question(item):\n",
    "    if '怎么' in item or '什么' in item or '哪' in item or '多少' in item or '谁' in item or '如何' in item:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def title_is_question(item):\n",
    "    if '怎么' in item or '什么' in item or '哪' in item or '多少' in item or '谁' in item or '如何' in item:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def prefix_title_leve_dist(item):\n",
    "    try:\n",
    "        return Levenshtein.distance(item['prefix'], item['title'])\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def prefix_title_leve_rate(item):\n",
    "    try:\n",
    "        return Levenshtein.ratio(item['prefix'], item['title'])\n",
    "    except:\n",
    "        return 0\n",
    "def get_word_w2v_model():\n",
    "    w2v_model_name = \"baike_26g_news_13g_novel_229g.bin\"\n",
    "    w2v_model_path = os.path.join(\"resources\", w2v_model_name)\n",
    "    w2v_model = KeyedVectors.load_word2vec_format(w2v_model_path, binary=True, unicode_errors=\"ignore\")\n",
    "    return w2v_model\n",
    "\n",
    "size = 100\n",
    "\n",
    "def char_cleaner(char):\n",
    "    if not isinstance(char, str):\n",
    "        char = \"null\"\n",
    "    pattern = re.compile(\"[^0-9a-zA-Z\\u4E00-\\u9FA5 ]\")\n",
    "    char = re.sub(pattern, \"\", char)\n",
    "    char = char.lower()\n",
    "    return char\n",
    "\n",
    "def _get_jieba_array(words):\n",
    "    words = char_cleaner(words)\n",
    "    seg_cut = jieba.lcut(words)\n",
    "\n",
    "    w2v_array = list()\n",
    "    for word in seg_cut:\n",
    "        try:\n",
    "            similar_list = word_w2v_model[word]\n",
    "            w2v_array.append(similar_list)\n",
    "        except KeyError:\n",
    "            continue\n",
    "\n",
    "    if not w2v_array:\n",
    "        w2v_array = [None] * size\n",
    "    else:\n",
    "        w2v_array = matutils.unitvec(np.array(w2v_array).mean(axis=0))\n",
    "        return w2v_array\n",
    "\n",
    "def get_query_w2v_similar(item):\n",
    "    item_dict = {}\n",
    "    query_prediction = item['query_prediction']\n",
    "    title = item['title']  # 等下再求下prefix得呢\n",
    "    prefix = item['prefix']\n",
    "    if query_prediction == '{}':\n",
    "        item_dict['prefix_max_similar'] = None\n",
    "        item_dict['prefix_mean_similar'] = None\n",
    "        item_dict['prefix_weight_similar'] = None\n",
    "        item_dict['title_max_similar'] = None\n",
    "        item_dict['title_mean_similar'] = None\n",
    "        item_dict['title_weight_similar'] = None\n",
    "        return item_dict\n",
    "\n",
    "    query_prediction = sorted(query_prediction.items(), key=itemgetter(1), reverse=True)\n",
    "    query_prediction = query_prediction[:3]\n",
    "    similar_list = []\n",
    "    weight_similar_list = []\n",
    "    title_array = _get_jieba_array(item['title'])\n",
    "    prefix_array = _get_jieba_array(item['prefix'])\n",
    "\n",
    "    for key, value in query_prediction:\n",
    "\n",
    "        query_cut_array = _get_jieba_array(key)\n",
    "        try:\n",
    "            w2v_similar = np.dot(query_cut_array, title_array)\n",
    "        except (KeyError, ZeroDivisionError, TypeError):\n",
    "            w2v_similar = np.nan\n",
    "\n",
    "        similar_list.append(w2v_similar)\n",
    "        weight_w2v_similar = w2v_similar * float(value)\n",
    "        weight_similar_list.append(weight_w2v_similar)\n",
    "\n",
    "        max_similar = np.nanmax(similar_list)\n",
    "        mean_similar = np.nanmean(similar_list)\n",
    "        weight_similar = np.nansum(weight_similar_list)\n",
    "\n",
    "        item_dict[\"title_max_similar\"] = max_similar\n",
    "        item_dict[\"title_mean_similar\"] = mean_similar\n",
    "        item_dict[\"title_weight_similar\"] = weight_similar\n",
    "\n",
    "    for key, value in query_prediction:\n",
    "\n",
    "        query_cut_array = _get_jieba_array(key)\n",
    "        try:\n",
    "            w2v_similar = np.dot(query_cut_array, prefix_array)\n",
    "        except (KeyError, ZeroDivisionError, TypeError):\n",
    "            w2v_similar = np.nan\n",
    "\n",
    "        similar_list.append(w2v_similar)\n",
    "        weight_w2v_similar = w2v_similar * float(value)\n",
    "        weight_similar_list.append(weight_w2v_similar)\n",
    "\n",
    "        max_similar = np.nanmax(similar_list)\n",
    "        mean_similar = np.nanmean(similar_list)\n",
    "        weight_similar = np.nansum(weight_similar_list)\n",
    "\n",
    "        item_dict[\"prefiix_max_similar\"] = max_similar\n",
    "        item_dict[\"prefix_mean_similar\"] = mean_similar\n",
    "        item_dict[\"prefix_weight_similar\"] = weight_similar\n",
    "\n",
    "        return item_dict\n",
    "\n",
    "def get_prefix_w2v_similar(item):\n",
    "    title = item['title']\n",
    "    prefix = item['prefix']\n",
    "    title_array = _get_jieba_array(item['title'])\n",
    "    prefix_array = _get_jieba_array(item['prefix'])\n",
    "    try:\n",
    "        w2v_similar = np.dot(prefix_array, title_array)\n",
    "    except (KeyError, ZeroDivisionError, TypeError):\n",
    "        w2v_similar = np.nan\n",
    "    return w2v_similar\n",
    "\n",
    "# prefix也要加上\n",
    "def get_query_sim_feature(data):\n",
    "    start = time.time()\n",
    "\n",
    "    data[\"item_dict\"] = data.apply(get_query_w2v_similar, axis=1)\n",
    "\n",
    "    data['prefix_title_sim'] = data.apply(get_prefix_w2v_similar, axis=1)\n",
    "\n",
    "    print(start - time.time())\n",
    "    return data\n",
    "\n",
    "def kmeans(data):\n",
    "    from sklearn.cluster import KMeans\n",
    "    features = ['prefix','title','tag']\n",
    "    for feature in features:\n",
    "        data[feature] = LabelEncoder().fit_transform(data[feature])\n",
    "    columns = ['query_prediction', 'label', 'flag', 'is_prefix_contains_upper_english', 'item_dict','query_word','query_score']\n",
    "    data_ = data.drop(columns,axis=1)\n",
    "    kmeans = KMeans(n_clusters=25,init='k-means++',max_iter=300,verbose=1,n_jobs=-1)\n",
    "    a = kmeans.fit_predict(data_)\n",
    "    data['kmeans'] = a\n",
    "    return data\n",
    "\n",
    "def co_feature_del(data):\n",
    "    threshold = 0.99\n",
    "    # Absolute value correlation matrix\n",
    "    corr_matrix = data.corr().abs()\n",
    "    # corr_matrix.head()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "    # upper.head()\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    print('There are %d columns to remove.' % (len(to_drop)))\n",
    "    data.drop(to_drop, axis=1, inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "def pre_data(data):\n",
    "    # 先看一下，没有加入作为特征得\n",
    "    train = data[data['flag'] == 1]\n",
    "    vali = data[data['flag'] == 2]\n",
    "    test = data[data['flag'] == 3]\n",
    "\n",
    "    train_X_data = train.drop(['query_prediction', 'label', 'flag', 'is_prefix_contains_upper_english', 'item_dict','query_word','query_score'],\n",
    "                              axis=1)\n",
    "    vali_X_data = vali.drop(['query_prediction', 'label', 'flag', 'is_prefix_contains_upper_english', 'item_dict','query_word','query_score'],\n",
    "                            axis=1)\n",
    "    test_X_data = test.drop(['query_prediction', 'label', 'flag', 'is_prefix_contains_upper_english', 'item_dict','query_word','query_score'],\n",
    "                            axis=1)\n",
    "    train_Y_data = train['label']\n",
    "    vali_label = vali['label']\n",
    "\n",
    "    return train_X_data,vali_X_data,test_X_data,train_Y_data,vali_label\n",
    "\n",
    "def lgb_test(train_X_data,vali_X_data,train_Y_data,vali_label):\n",
    "\n",
    "    predict = []\n",
    "    clf = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt', subsample=1, colsample_bytree=1,\n",
    "    max_depth=-1, n_estimators=10000, objective='binary',min_child_weight = 10,\n",
    "    subsample_freq=1, num_leaves=127, reg_alpha=0,reg_lambda = 1.3,\n",
    "    random_state=2018, n_jobs=-1, learning_rate=0.1)\n",
    "\n",
    "    clf.fit(train_X_data, train_Y_data,eval_set=[(train_X_data,train_Y_data),(vali_X_data,vali_label)], eval_metric='logloss',verbose = 50, early_stopping_rounds=100)\n",
    "    predict = clf.predict_proba(vali_X_data,num_iteration=clf.best_iteration_)\n",
    "    return predict,clf\n",
    "\n",
    "def find_best_thr(predict,vali_label):\n",
    "    max = 0.0\n",
    "    max_i =0.0\n",
    "    predict = pd.DataFrame(predict)\n",
    "    predict = predict[1]\n",
    "    predict = pd.DataFrame(predict)\n",
    "    for i in np.arange(0.25, 0.4500, 0.001):\n",
    "        f1 = f1_score(vali_label, predict[1].map(lambda x: 0 if x < i else 1))\n",
    "        if (f1 > max):\n",
    "            max = f1_score(vali_label, predict[1].map(lambda x: 0 if x <= i else 1))\n",
    "            max_i = i\n",
    "    print('最大f1为', max)\n",
    "    print('此时阈值为:', max_i)\n",
    "\n",
    "    return max,max_i\n",
    "\n",
    "def get_feature0(item):\n",
    "    try:\n",
    "        return item['item_dict']['title_max_similar']\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def get_feature1(item):\n",
    "    try:\n",
    "        return item['item_dict']['title_mean_similar']\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def get_feature2(item):\n",
    "    try:\n",
    "        return item['item_dict']['title_weight_similar']\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def get_feature3(item):\n",
    "    try:\n",
    "        return item['item_dict']['prefiix_max_similar']\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def get_feature4(item):\n",
    "    try:\n",
    "        return item['item_dict']['prefix_mean_similar']\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def get_feature5(item):\n",
    "    try:\n",
    "        return item['item_dict']['prefix_weight_similar']\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def get_feature6(item):\n",
    "    try:\n",
    "        return max(item['query_score'])\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def get_feature7(item):\n",
    "    try:\n",
    "        return min(item['query_score'])\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "def get_feature8(item):\n",
    "    try:\n",
    "        return np.mean(item['query_score'])\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "mode = \"train\"\n",
    "data = get_data()\n",
    "data = run_process(data)\n",
    "prefix_dic = get_prefix_query_dic(data)\n",
    "data['query_prediction'] = data.apply(null_query_prediction_process,axis=1)\n",
    "data['query_prediction'] = data.apply(query_process,axis=1)\n",
    "data['prefix'] = data.apply(get_complete_prefix,axis=1)  #把complete_prefix也当作基础特征\n",
    "data = get_query_list_feature(data)\n",
    "print(1)\n",
    "data['prefix_word_len'] = data['prefix'].apply(lambda x: get_word_length(x))\n",
    "data['title_word_len'] = data['title'].apply(lambda x: get_word_length(x))\n",
    "data['title-prefix_word_len'] = data['title_word_len'] - data['prefix_word_len']\n",
    "data['prefix_is_question'] = data['prefix'].apply(lambda x: prefix_is_question(x))\n",
    "data['title_is_question'] = data['title'].apply(lambda x: title_is_question(x))\n",
    "data['title_is_network'] = data['title'].apply(lambda x: title_is_network(x))\n",
    "data['prefix_is_network'] = data['prefix'].apply(lambda x: prefix_is_network(x))\n",
    "data['prefix_title_leve_dist'] = data.apply(prefix_title_leve_dist, axis=1)\n",
    "data['prefix_title_leve_rate'] = data.apply(prefix_title_leve_rate, axis=1)\n",
    "print(2)\n",
    "data['query_prediction_len'] = data['query_word'].apply(lambda x: len(x))\n",
    "data['prefix_len'] = data['prefix'].apply(lambda x: len(x))\n",
    "data['title_len'] = data['title'].apply(lambda x: len(x))\n",
    "data['title-prefix_len'] = data['title_len'] - data['prefix_len']\n",
    "data['title_is_in_query'] = data.apply(title_is_in_query, axis=1)\n",
    "data['is_prefix_in_title'] = data.apply(prefix_is_in_title, axis=1)\n",
    "print('start_w2v_feature')\n",
    "word_w2v_model = get_word_w2v_model()\n",
    "data = get_query_sim_feature(data)\n",
    "\n",
    "data['title_max_similar'] = data.apply(get_feature0, axis=1)\n",
    "data['title_mean_similar'] = data.apply(get_feature1, axis=1)\n",
    "data['title_weight_similar'] = data.apply(get_feature2, axis=1)\n",
    "data['prefix_max_similar'] = data.apply(get_feature3, axis=1)\n",
    "data['prefix_mean_similar'] = data.apply(get_feature4, axis=1)\n",
    "data['prefix_weight_similar'] = data.apply(get_feature5, axis=1)\n",
    "data['query_score_max'] = data.apply(get_feature6, axis=1)\n",
    "data['query_score_min'] = data.apply(get_feature7, axis=1)\n",
    "data['query_score_mean'] = data.apply(get_feature8, axis=1)\n",
    "\n",
    "print('basic_feature_finish')\n",
    "\n",
    "columns = ['title-prefix_len',\n",
    "       'query_score_max', 'query_score_mean', 'query_score_min',\n",
    "       'title_is_in_query', 'is_prefix_in_title'\n",
    "       , 'title_max_similar',\n",
    "       'title_mean_similar', 'title_weight_similar','prefix_title_sim','prefix_weight_similar','prefix_mean_similar','prefix_max_similar']\n",
    "for column in columns:\n",
    "    data[column] = data[column].fillna(data[column].mean())\n",
    "\n",
    "\n",
    "data.to_csv(\"/home/ccit/tkhoon/liuyunEtlData/feature.csv\",index=False)\n",
    "\n",
    "print('baisc_feature_saved')\n",
    "data['prefix_title_sim_bin'] = pd.qcut(data['prefix_title_sim'],8)\n",
    "data['prefix_title_sim_bin'] = pd.factorize(data['prefix_title_sim_bin'])[0]\n",
    "\n",
    "data['title_weight_similar_bin'] = pd.qcut(data['title_weight_similar'],10)\n",
    "data['title_weight_similar_bin'] = pd.factorize(data['title_weight_similar_bin'])[0]\n",
    "\n",
    "data['title_mean_similar_bin'] = pd.qcut(data['title_mean_similar'],5)\n",
    "data['title_mean_similar_bin'] = pd.factorize(data['title_mean_similar_bin'])[0]\n",
    "\n",
    "data['title_max_similar_bin'] = pd.qcut(data['title_max_similar'],5)\n",
    "data['title_max_similar_bin']  = pd.factorize(data['title_max_similar_bin'])[0]\n",
    "\n",
    "data['prefix_weight_similar_bin'] = pd.qcut(data['prefix_weight_similar'],10)\n",
    "data['prefix_weight_similar_bin'] = pd.factorize(data['prefix_weight_similar_bin'])[0]\n",
    "\n",
    "data['prefix_mean_similar_bin'] = pd.qcut(data['prefix_mean_similar'],5)\n",
    "data['prefix_mean_similar_bin'] = pd.factorize(data['prefix_mean_similar_bin'])[0]\n",
    "\n",
    "data['prefix_max_similar_bin'] = pd.qcut(data['prefix_max_similar'],3)\n",
    "data['prefix_max_similar_bin']  = pd.factorize(data['prefix_max_similar_bin'])[0]\n",
    "\n",
    "print('start_kmeans')\n",
    "data = kmeans(data)\n",
    "print('start_run_feature')\n",
    "\n",
    "\n",
    "features = ['prefix', 'title', 'tag','is_prefix_in_title','title_is_in_query'\n",
    "            ,'prefix_word_len','title_word_len','prefix_is_question','prefix_is_network','query_score_mean','title_weight_similar'\n",
    "           ,'query_prediction_len','prefix_len','title_len','prefix_weight_similar']\n",
    "for feature in features:\n",
    "    a = data[feature].value_counts().to_dict()\n",
    "    data[feature+'_count'] = data[feature].apply(lambda x:a[x])\n",
    "    del a\n",
    "    gc.collect()\n",
    "    print(feature)\n",
    "print('part_1_finish')\n",
    "gc.collect()\n",
    "\n",
    "for  i in range(len(features)):\n",
    "    for j in range(i+1,len(features)):\n",
    "        new_feature = features[i]+'_'+features[j]\n",
    "        data[new_feature] = data[features[i]].astype(str) + '_' + data[features[j]].astype(str)\n",
    "        data[new_feature] = LabelEncoder().fit_transform(data[new_feature])\n",
    "        new_feature_count = new_feature + '_count'\n",
    "        a = data[new_feature].value_counts().to_dict()\n",
    "        data[new_feature_count] = data[new_feature].apply(lambda x : a[x])\n",
    "        gc.collect()\n",
    "        del a\n",
    "        print(i)\n",
    "print('part2_finish')\n",
    "gc.collect()\n",
    "\n",
    "pos_features = ['title_weight_similar_bin', 'title_mean_similar_bin','title_max_similar_bin','prefix_title_sim_bin','query_prediction_len','prefix_len','title_len',\n",
    "                'title-prefix_len','prefix_word_len','title_word_len','title-prefix_word_len','prefix_max_similar_bin','prefix_mean_similar_bin',\n",
    "               'prefix_weight_similar_bin']\n",
    "for feature in pos_features:\n",
    "    train = data[(data['flag'] == 1)]\n",
    "    temp = train.groupby(feature,as_index=False)['label'].agg({feature+'_click_':'sum',feature+'_count_':'count'})\n",
    "    temp[feature+'_ctr_'] = temp[feature+'_click_'] / (temp[feature+'_count_']+5)\n",
    "    data = pd.merge(data,temp,on=feature,how='left')\n",
    "    del train\n",
    "    del temp\n",
    "    gc.collect()\n",
    "    print(feature)\n",
    "print('part3_finish')\n",
    "\n",
    "features = ['prefix','title','tag']\n",
    "for feature in features:\n",
    "    data[feature] = LabelEncoder().fit_transform(data[feature])\n",
    "\n",
    "\n",
    "print('feature_del')\n",
    "data = co_feature_del(data)\n",
    "print('lgb_test')\n",
    "train_X_data,vali_X_data,test_X_data,train_Y_data,vali_label = pre_data(data)\n",
    "predict,clf = lgb_test(train_X_data,vali_X_data,train_Y_data,vali_label)\n",
    "\n",
    "best_f1,best_thr = find_best_thr(predict,vali_label)\n",
    "\n",
    "print('best_f1:',best_f1)\n",
    "print('best_thr:',best_thr)\n",
    "\n",
    "submit = clf.predict_proba(test_X_data,num_iteration=clf.best_iteration_)\n",
    "submit = pd.DataFrame(submit)\n",
    "submit.to_csv(\"/home/ccit/tkhoon/liuyunEtlData/feature.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# duqu shuju banben"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['prefix','title','tag']\n",
    "for feature in features:\n",
    "    data[feature] = LabelEncoder().fit_transform(data[feature])\n",
    "columns = ['query_prediction', 'label', 'flag', 'is_prefix_contains_upper_english', 'item_dict','query_word','query_score']\n",
    "data_ = data.drop(columns,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_kmeans\n",
      "Initialization complete\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Initialization complete\n",
      "Iteration 0, inertia 3515112098289364.5\n",
      "start iteration\n",
      "done sorting\n",
      "start iteration\n",
      "done sorting\n",
      "Initialization complete\n",
      "end inner loop\n",
      "end inner loop\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Initialization complete\n",
      "Iteration 0, inertia 3700553427652613.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 3281626668368010.0\n",
      "start iteration\n",
      "done sorting\n",
      "start iteration\n",
      "done sorting\n",
      "Initialization complete\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 0, inertia 3598559032286564.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 3399592215004150.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 3483082362822402.0\n",
      "start iteration\n",
      "done sorting\n",
      "Initialization complete\n",
      "Iteration 2, inertia 3217975337403734.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 1, inertia 3313006297703744.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 3789875526285662.5\n",
      "start iteration\n",
      "done sorting\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 2, inertia 3322697665706784.0\n",
      "start iteration\n",
      "done sorting\n",
      "Initialization complete\n",
      "end inner loop\n",
      "Iteration 1, inertia 3306641250463109.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 3208343486781786.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 3501325226811814.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 3293685600814874.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 3, inertia 3185386409980284.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 3270790137480465.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Initialization complete\n",
      "Iteration 3, inertia 3167904183312313.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 3384484082637828.5\n",
      "start iteration\n",
      "done sorting\n",
      "Initialization complete\n",
      "end inner loop\n",
      "Iteration 0, inertia 3449388655554166.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 4, inertia 3278343639683163.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 3, inertia 3246575937434301.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "end inner loop\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 4, inertia 3151391043279751.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 3, inertia 3310975396375845.0\n",
      "start iteration\n",
      "done sorting\n",
      "Initialization complete\n",
      "end inner loop\n",
      "Iteration 5, inertia 3270594617568240.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 3236123731291790.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 0, inertia 3488716670355125.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 5, inertia 3143824972352547.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 3475277990632741.0\n",
      "start iteration\n",
      "done sorting\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 3261260358227783.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 6, inertia 3265513667251382.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 3174154204273555.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 5, inertia 3230699163089944.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 1, inertia 3330570610598751.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 6, inertia 3140290619814899.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 3238228611941052.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 3262214358902876.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 3226078289182866.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 2, inertia 3270880369461039.5\n",
      "start iteration\n",
      "end inner loop\n",
      "done sorting\n",
      "Iteration 1, inertia 3229792688639863.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 0, inertia 3645502672198309.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 7, inertia 3137111188186006.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 3222066632715555.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 8, inertia 3260798800590114.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 3221097991810286.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 3, inertia 3239931435922680.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 8, inertia 3134532330366263.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 7, inertia 3210629445998918.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 9, inertia 3259760152520257.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 0, inertia 3567052979000566.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 1, inertia 3313624429596857.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 8, inertia 3212752219658931.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 4, inertia 3227090707586197.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 3169187943898580.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 3133247564098254.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 3202083235327963.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 3254655587277360.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 3201486566556121.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 3220310003969786.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 3160431273233974.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 3441982882901096.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 10, inertia 3131456685450504.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 9, inertia 3195661777290909.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 3248267820045497.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 3195037308570366.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 3214473211595849.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 3129154260209553.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 3189993282393226.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 12, inertia 3241322473802002.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 11, inertia 3193058795895647.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 3209315004353830.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 1, inertia 3362840865956314.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 12, inertia 3126017236396228.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 2, inertia 3265970555282453.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 6, inertia 3163391375265404.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 11, inertia 3186420455692225.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 3233939221434809.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 12, inertia 3190573273349660.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 3205168128836863.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 3121815756441367.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 3183688183084383.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 14, inertia 3225796405522524.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 13, inertia 3187639206594977.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 3118734774070547.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 2, inertia 3388196486061375.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 9, inertia 3203275859740543.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 14, inertia 3118498398476036.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 3181775252633632.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 15, inertia 3217437094404966.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 14, inertia 3185766179809313.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 3202643693901966.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 3113279583268071.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 3211207099442874.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 14, inertia 3180683813337076.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 3, inertia 3245652252888933.5\n",
      "start iteration\n",
      "end inner loop\n",
      "done sorting\n",
      "Iteration 7, inertia 3159389692451440.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 2, inertia 3291470289456611.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 15, inertia 3184617044078598.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 11, inertia 3201054136117692.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 3108239873553803.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 3205441552747970.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 15, inertia 3178995437371760.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 16, inertia 3183353274476258.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 3200350951779363.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 3, inertia 3354784480179386.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 4, inertia 3099113509880454.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 17, inertia 3104111711386548.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 3198837758160951.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 16, inertia 3177187454245184.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 17, inertia 3182145384364640.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 3200129630177920.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 3100530232042262.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 19, inertia 3193622682274902.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 17, inertia 3175943038197591.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 18, inertia 3181506080805523.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 3200053089672366.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 3157226110012580.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 3235575474711124.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 19, inertia 3098040496367374.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 20, inertia 3188392330639520.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 3174920410888498.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 3, inertia 3253549351175079.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 19, inertia 3181067544354132.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 15, inertia 3200035144811593.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 20, inertia 3095958946559332.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 21, inertia 3183932717089026.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 19, inertia 3174274721171497.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 5, inertia 3091585194782272.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 4, inertia 3323847222344533.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 20, inertia 3180288917691612.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 16, inertia 3200030833747816.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 21, inertia 3094505380185196.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 22, inertia 3180902875224306.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 20, inertia 3173691664258729.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 3156163425821820.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 17, inertia 3200025306826302.0\n",
      "center shift 2.957330e+02 within tolerance 9.643441e+04\n",
      "Iteration 21, inertia 3179939469634276.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 22, inertia 3093906875716027.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 23, inertia 3177193912296542.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 5, inertia 3230022529447800.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 21, inertia 3173291674514830.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 22, inertia 3179726447076838.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 4, inertia 3231737929911272.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 23, inertia 3093613670070254.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 24, inertia 3174390053412401.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 22, inertia 3173054167693789.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 23, inertia 3179625398012749.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 24, inertia 3093322511198931.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 25, inertia 3172017708678281.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 5, inertia 3298044130301866.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 6, inertia 3088112239803137.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 23, inertia 3172892916174895.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 24, inertia 3179528382071522.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 25, inertia 3092331878733867.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 26, inertia 3170174880289816.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 24, inertia 3172541917710582.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 3227152776936013.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 10, inertia 3155095138894522.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 25, inertia 3179194499402475.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 26, inertia 3091197371153690.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 27, inertia 3168418771368469.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 25, inertia 3172346406102021.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 5, inertia 3218270340742502.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 26, inertia 3178833728045829.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 27, inertia 3090566734362286.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 28, inertia 3166567202419231.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 26, inertia 3172287100348398.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 27, inertia 3178199253661439.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 7, inertia 3084397153714131.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 6, inertia 3277446610375477.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 28, inertia 3090253478808496.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 29, inertia 3165368517849143.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 27, inertia 3172255352754033.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 28, inertia 3177774727327883.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 29, inertia 3090156424210133.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 30, inertia 3164575645944895.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 7, inertia 3223876361879601.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 28, inertia 3172233824560916.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 3151372823462602.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 6, inertia 3206178385525017.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 29, inertia 3177393756577984.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 30, inertia 3089511300035565.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 31, inertia 3164047406430610.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 29, inertia 3172200029221898.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 30, inertia 3176898917463022.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 3081314703440711.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 7, inertia 3265238329486796.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 31, inertia 3089117858975541.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 32, inertia 3163763668851623.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 30, inertia 3171974455800034.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 31, inertia 3176461057126718.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 32, inertia 3088847375929864.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 33, inertia 3163300140482900.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 7, inertia 3198444774840773.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 31, inertia 3171626519784121.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 32, inertia 3175865593188822.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 3219347973724403.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 3147809529554449.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 33, inertia 3088738633009872.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 34, inertia 3162862957150784.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 32, inertia 3171366023115222.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 33, inertia 3173309732394064.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 34, inertia 3088382904420736.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 9, inertia 3078234888204767.5\n",
      "end inner loop\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 35, inertia 3162624411563571.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 33, inertia 3171201026565929.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 8, inertia 3252836895682371.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 34, inertia 3169699337709549.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 35, inertia 3088025100679310.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 8, inertia 3194203963514746.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 36, inertia 3162465409416788.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 34, inertia 3170956268875853.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 35, inertia 3166443887066006.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 36, inertia 3087726792074335.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 9, inertia 3212214946660099.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 13, inertia 3146093874286658.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 37, inertia 3162298379846289.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 35, inertia 3170647160913718.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 36, inertia 3164432081304743.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 37, inertia 3087507078340865.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 38, inertia 3162177668881261.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 36, inertia 3170484380562124.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 37, inertia 3163340529620852.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 3074732362811373.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 9, inertia 3243295517092891.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 9, inertia 3190619331297526.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 38, inertia 3087371850947285.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 39, inertia 3162093743675950.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 37, inertia 3170408630656485.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 38, inertia 3162447313287982.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 39, inertia 3087303725450100.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 40, inertia 3162025950798417.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 38, inertia 3170316127930138.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 39, inertia 3162027584936991.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 14, inertia 3144507851332818.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 10, inertia 3204481240618807.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 40, inertia 3087276658220288.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 41, inertia 3161963359407785.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 39, inertia 3170234605129252.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 40, inertia 3161774956932866.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 41, inertia 3087271306115837.5\n",
      "center shift 2.974280e+02 within tolerance 9.643441e+04\n",
      "Iteration 42, inertia 3161918118818719.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 10, inertia 3238574506674446.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 40, inertia 3169945441780285.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 10, inertia 3187250000915410.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 11, inertia 3072387836727818.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 41, inertia 3160271262302235.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 43, inertia 3161875912510221.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 41, inertia 3169679330673809.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 42, inertia 3158986546222983.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 44, inertia 3161785307556591.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 42, inertia 3169506134620724.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 15, inertia 3143877806260447.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 11, inertia 3197295975274729.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 43, inertia 3157873402358436.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 11, inertia 3184841765009789.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 11, inertia 3235403812961216.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 45, inertia 3161520282371626.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 43, inertia 3169425599043723.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 12, inertia 3070458751372787.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 44, inertia 3156901886399497.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 12, inertia 3183061759501445.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 46, inertia 3161326461929698.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 44, inertia 3169373222668895.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 45, inertia 3155794423707637.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 47, inertia 3161177734800282.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 16, inertia 3143474675389146.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 45, inertia 3169270790675455.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 12, inertia 3191341020880193.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 46, inertia 3154082979362215.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 3181838823626014.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 48, inertia 3160820706354566.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 46, inertia 3169129308144536.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 12, inertia 3230287585361503.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 13, inertia 3069383990932873.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 47, inertia 3152811130331569.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 49, inertia 3160604882308521.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 47, inertia 3168476183384876.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 3180852781967818.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 48, inertia 3149822821461869.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 3143279116721879.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 13, inertia 3187198042912670.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 50, inertia 3160261755674610.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 48, inertia 3167908278363576.0\n",
      "start iteration\n",
      "done sorting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 15, inertia 3179921422605791.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 49, inertia 3146442481724631.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 13, inertia 3225879442874979.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 14, inertia 3068206456485170.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 51, inertia 3160018169762413.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 49, inertia 3167311651305387.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 3179135781481431.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 50, inertia 3143656811537468.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 52, inertia 3159895531477936.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 50, inertia 3167035733750926.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 17, inertia 3178298242672606.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 18, inertia 3143186189113356.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 51, inertia 3142112144737346.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 14, inertia 3184189881330290.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 53, inertia 3159821424747001.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 51, inertia 3166457222285422.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 3177441192561971.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 52, inertia 3141003953864559.0\n",
      "end inner loop\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 14, inertia 3221910430384997.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 54, inertia 3159783204072456.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 15, inertia 3067180963299890.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 19, inertia 3176770800175300.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 53, inertia 3140324471464336.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 52, inertia 3165709420439321.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 55, inertia 3159726763045902.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 19, inertia 3143165011763205.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 20, inertia 3176258770817357.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 53, inertia 3164715616003459.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 15, inertia 3180739901771296.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 54, inertia 3140014129395891.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 56, inertia 3153272028943882.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 21, inertia 3175514382964470.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 54, inertia 3161256662300336.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 15, inertia 3219423707712593.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 55, inertia 3139761963848151.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 3066393637327435.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 57, inertia 3147154827984271.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 22, inertia 3174900440596572.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 55, inertia 3155854042835923.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 56, inertia 3138362233278295.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 20, inertia 3143159857429415.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 58, inertia 3142685460592799.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 3178387307451338.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 23, inertia 3173374852073981.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 56, inertia 3151601742124940.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 57, inertia 3137574364830096.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 59, inertia 3139867157691570.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 16, inertia 3218062945583496.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 17, inertia 3066111014779212.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 57, inertia 3147500443201271.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 24, inertia 3171552459339086.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 58, inertia 3137315986468550.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 60, inertia 3138966059677249.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 25, inertia 3170209034152130.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 58, inertia 3144067259892941.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 59, inertia 3137278233522836.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 21, inertia 3143158244340289.5\n",
      "center shift 3.047208e+02 within tolerance 9.643441e+04\n",
      "Iteration 17, inertia 3177237561635305.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 61, inertia 3138220513881475.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 26, inertia 3169162567193638.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 59, inertia 3140548509570992.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 60, inertia 3137262970005329.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 62, inertia 3137799188215540.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 18, inertia 3065966286486793.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 17, inertia 3217260594988928.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 27, inertia 3168421677000711.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 61, inertia 3137257274326818.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 60, inertia 3137809861319123.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 3176537961028530.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 63, inertia 3137297985867122.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 28, inertia 3167443215270248.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 62, inertia 3137243205069258.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 19, inertia 3065885569859190.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 61, inertia 3135579500380956.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 18, inertia 3216270518456828.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 64, inertia 3136868172700370.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 19, inertia 3176171637170840.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 29, inertia 3166093154517843.5\n",
      "start iteration\n",
      "end inner loop\n",
      "done sorting\n",
      "Iteration 63, inertia 3137235869436312.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 62, inertia 3134582228189957.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 65, inertia 3136692117217894.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 20, inertia 3065844900990140.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 19, inertia 3215017367431057.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 30, inertia 3165175159780538.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 63, inertia 3134092843203830.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 64, inertia 3137233982182931.5\n",
      "center shift 1.733245e+02 within tolerance 9.643441e+04\n",
      "end inner loop\n",
      "Iteration 20, inertia 3175992418363130.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 66, inertia 3136589764624563.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 31, inertia 3164738808737029.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 64, inertia 3133380927603255.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 21, inertia 3065817574728242.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 20, inertia 3212595889849589.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 67, inertia 3136550219488606.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 21, inertia 3175564212905667.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 32, inertia 3164573947129605.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 65, inertia 3133044215812489.5\n",
      "start iteration\n",
      "done sorting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end inner loop\n",
      "Iteration 68, inertia 3136537549153962.0\n",
      "center shift 2.394081e+02 within tolerance 9.643441e+04\n",
      "Iteration 22, inertia 3065798270152123.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 21, inertia 3208056259978383.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 33, inertia 3164524838051173.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 66, inertia 3132894982512498.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 22, inertia 3174856276558729.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 34, inertia 3164494294986230.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 67, inertia 3132823910943393.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 23, inertia 3065785456780789.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 22, inertia 3204569779336109.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 35, inertia 3164379885412645.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 23, inertia 3171057413556334.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 68, inertia 3132782062163684.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 24, inertia 3065777497528083.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 23, inertia 3198073421692894.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 36, inertia 3164117062655252.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 69, inertia 3132760000060893.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 24, inertia 3168597505846396.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 37, inertia 3163823231719602.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 25, inertia 3065772129414153.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 70, inertia 3132754899774055.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 24, inertia 3192483957166744.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 25, inertia 3167430385117351.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 38, inertia 3163394218923885.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 71, inertia 3132744274429307.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 26, inertia 3065767835797054.5\n",
      "center shift 2.776304e+02 within tolerance 9.643441e+04\n",
      "Iteration 25, inertia 3187018098676585.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 39, inertia 3163043317597313.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 72, inertia 3132739399106260.5\n",
      "center shift 2.794135e+02 within tolerance 9.643441e+04\n",
      "Iteration 26, inertia 3166248133973169.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 26, inertia 3182697346572511.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 40, inertia 3162665277319017.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 27, inertia 3165317206555038.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 27, inertia 3179311505206533.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 41, inertia 3162440959183699.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 28, inertia 3164456627718872.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 42, inertia 3162283106187851.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 28, inertia 3177875560548457.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 29, inertia 3163993553696650.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 43, inertia 3156499483900718.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 29, inertia 3177090797312804.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 30, inertia 3163640919935284.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 44, inertia 3149927430090881.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 30, inertia 3176668973090838.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 31, inertia 3163253122743391.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 45, inertia 3145389688871489.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 31, inertia 3176431881320421.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 32, inertia 3162946194990123.5\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 46, inertia 3142517306412766.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "end inner loop\n",
      "Iteration 32, inertia 3176351258582819.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 47, inertia 3141680705028456.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 33, inertia 3162749595966583.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 33, inertia 3176311769473662.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 48, inertia 3141172711356087.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 34, inertia 3162608149606052.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 34, inertia 3176291484109792.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 49, inertia 3140782415093172.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 35, inertia 3162527929596135.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 35, inertia 3176231768608341.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 50, inertia 3140338496371105.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 36, inertia 3162411873513617.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 36, inertia 3176187493488148.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 51, inertia 3140101575613777.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 37, inertia 3162360871340203.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 37, inertia 3176160936018264.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 52, inertia 3139849645597440.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 38, inertia 3162305161563017.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 53, inertia 3139740650851865.0\n",
      "start iteration\n",
      "done sorting\n",
      "Iteration 38, inertia 3176153522981823.0\n",
      "center shift 2.322786e+02 within tolerance 9.643441e+04\n",
      "end inner loop\n",
      "Iteration 39, inertia 3162264950990084.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 54, inertia 3139710065165190.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 40, inertia 3162155703869019.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 55, inertia 3139698447847403.0\n",
      "center shift 2.822920e+02 within tolerance 9.643441e+04\n",
      "Iteration 41, inertia 3161978219684857.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 42, inertia 3161761765734579.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 43, inertia 3161571991675306.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 44, inertia 3161307237332149.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 45, inertia 3160983958848611.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 46, inertia 3160716953849159.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 47, inertia 3160524859233535.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 48, inertia 3160443991398855.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 49, inertia 3160421113326558.5\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 50, inertia 3160411312000335.0\n",
      "start iteration\n",
      "done sorting\n",
      "end inner loop\n",
      "Iteration 51, inertia 3160408506394867.0\n",
      "center shift 2.298245e+02 within tolerance 9.643441e+04\n",
      "run_feature\n",
      "kmeans\n",
      "prefix\n",
      "title\n",
      "tag\n",
      "is_prefix_in_title\n",
      "title_is_in_query\n",
      "prefix_word_len\n",
      "title_word_len\n",
      "prefix_is_question\n",
      "prefix_is_network\n",
      "query_score_mean\n",
      "title_weight_similar\n",
      "query_prediction_len\n",
      "prefix_len\n",
      "title_len\n",
      "prefix_weight_similar\n",
      "part_1_finish\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "12\n",
      "12\n",
      "12\n",
      "13\n",
      "13\n",
      "14\n",
      "part2_finish\n",
      "kmeans\n",
      "title_weight_similar_bin\n",
      "title_mean_similar_bin\n",
      "title_max_similar_bin\n",
      "prefix_title_sim_bin\n",
      "query_prediction_len\n",
      "prefix_len\n",
      "title_len\n",
      "title-prefix_len\n",
      "prefix_word_len\n",
      "title_word_len\n",
      "title-prefix_word_len\n",
      "prefix_max_similar_bin\n",
      "prefix_mean_similar_bin\n",
      "prefix_weight_similar_bin\n",
      "part3_finish\n",
      "run_co_feature_del\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import Levenshtein\n",
    "from gensim import matutils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import warnings\n",
    "import os\n",
    "import jieba\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from operator import itemgetter\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold as skf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from sklearn.metrics import f1_score\n",
    "import gc\n",
    "\n",
    "def kmeans(data):\n",
    "    from sklearn.cluster import KMeans\n",
    "    features = ['prefix','title','tag']\n",
    "    for feature in features:\n",
    "        data[feature] = LabelEncoder().fit_transform(data[feature])\n",
    "    columns = ['query_prediction', 'label', 'flag', 'is_prefix_contains_upper_english', 'item_dict','query_word','query_score']\n",
    "    data_ = data.drop(columns,axis=1)\n",
    "    kmeans = KMeans(n_clusters=25,init='k-means++',max_iter=300,verbose=1,n_jobs=-1)\n",
    "    a = kmeans.fit_predict(data_)\n",
    "    data['kmeans'] = a\n",
    "    del data_\n",
    "    return data\n",
    "\n",
    "def co_feature_del(data):\n",
    "    threshold = 0.99\n",
    "    # Absolute value correlation matrix\n",
    "    corr_matrix = data.corr().abs()\n",
    "    # corr_matrix.head()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "    # upper.head()\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    print('There are %d columns to remove.' % (len(to_drop)))\n",
    "    data.drop(to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    del upper\n",
    "    del to_drop\n",
    "    del corr_matrix\n",
    "    return data\n",
    "\n",
    "def pre_data(data):\n",
    "    # 先看一下，没有加入作为特征得\n",
    "    train = data[data['flag'] == 1]\n",
    "    vali = data[data['flag'] == 2]\n",
    "    test = data[data['flag'] == 3]\n",
    "\n",
    "    train_X_data = train.drop(['query_prediction', 'label', 'flag', 'is_prefix_contains_upper_english', 'item_dict','query_word','query_score'],\n",
    "                              axis=1)\n",
    "    vali_X_data = vali.drop(['query_prediction', 'label', 'flag', 'is_prefix_contains_upper_english', 'item_dict','query_word','query_score'],\n",
    "                            axis=1)\n",
    "    test_X_data = test.drop(['query_prediction', 'label', 'flag', 'is_prefix_contains_upper_english', 'item_dict','query_word','query_score'],\n",
    "                            axis=1)\n",
    "    train_Y_data = train['label']\n",
    "    vali_label = vali['label']\n",
    "    \n",
    "    del train\n",
    "    del vali\n",
    "    del test\n",
    "    \n",
    "    return train_X_data,vali_X_data,test_X_data,train_Y_data,vali_label\n",
    "\n",
    "def lgb_test(train_X_data,vali_X_data,train_Y_data,vali_label):\n",
    "\n",
    "    predict = []\n",
    "    clf = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt', subsample=1, colsample_bytree=1,\n",
    "    max_depth=-1, n_estimators=10000, objective='binary',min_child_weight = 10,\n",
    "    subsample_freq=1, num_leaves=127, reg_alpha=0,reg_lambda = 1.3,\n",
    "    random_state=2018, n_jobs=-1, learning_rate=0.1)\n",
    "\n",
    "    clf.fit(train_X_data, train_Y_data,eval_set=[(train_X_data,train_Y_data),(vali_X_data,vali_label)], eval_metric='logloss',verbose = 50, early_stopping_rounds=100)\n",
    "    predict = clf.predict_proba(vali_X_data,num_iteration=clf.best_iteration_)\n",
    "    return predict,clf\n",
    "\n",
    "def find_best_thr(predict,vali_label):\n",
    "    max = 0.0\n",
    "    max_i =0.0\n",
    "    predict = pd.DataFrame(predict)\n",
    "    predict = predict[1]\n",
    "    predict = pd.DataFrame(predict)\n",
    "    for i in np.arange(0.25, 0.4500, 0.001):\n",
    "        f1 = f1_score(vali_label, predict[1].map(lambda x: 0 if x < i else 1))\n",
    "        if (f1 > max):\n",
    "            max = f1_score(vali_label, predict[1].map(lambda x: 0 if x <= i else 1))\n",
    "            max_i = i\n",
    "    print('最大f1为', max)\n",
    "    print('此时阈值为:', max_i)\n",
    "\n",
    "    return max,max_i\n",
    "\n",
    "data = pd.read_csv(\"/home/ccit/tkhoon/liuyunEtlData/feature.csv\")\n",
    "data['prefix'] = data['prefix'].astype(str)\n",
    "data['title'] = data['title'].astype(str)\n",
    "data['prefix_max_similar'] = data['prefix_max_similar'].fillna(data['prefix_max_similar'].mean())\n",
    "data['prefix_title_sim_bin'] = pd.qcut(data['prefix_title_sim'],8)\n",
    "data['prefix_title_sim_bin'] = pd.factorize(data['prefix_title_sim_bin'])[0]\n",
    "\n",
    "data['title_weight_similar_bin'] = pd.qcut(data['title_weight_similar'],10)\n",
    "data['title_weight_similar_bin'] = pd.factorize(data['title_weight_similar_bin'])[0]\n",
    "\n",
    "data['title_mean_similar_bin'] = pd.qcut(data['title_mean_similar'],5)\n",
    "data['title_mean_similar_bin'] = pd.factorize(data['title_mean_similar_bin'])[0]\n",
    "\n",
    "data['title_max_similar_bin'] = pd.qcut(data['title_max_similar'],5)\n",
    "data['title_max_similar_bin']  = pd.factorize(data['title_max_similar_bin'])[0]\n",
    "\n",
    "data['prefix_weight_similar_bin'] = pd.qcut(data['prefix_weight_similar'],10)\n",
    "data['prefix_weight_similar_bin'] = pd.factorize(data['prefix_weight_similar_bin'])[0]\n",
    "\n",
    "data['prefix_mean_similar_bin'] = pd.qcut(data['prefix_mean_similar'],5)\n",
    "data['prefix_mean_similar_bin'] = pd.factorize(data['prefix_mean_similar_bin'])[0]\n",
    "\n",
    "data['prefix_max_similar_bin'] = pd.qcut(data['prefix_max_similar'],3)\n",
    "data['prefix_max_similar_bin']  = pd.factorize(data['prefix_max_similar_bin'])[0]\n",
    "print('run_kmeans')\n",
    "data = kmeans(data)\n",
    "print('run_feature')\n",
    "gc.collect()\n",
    "\n",
    "features = ['kmeans','prefix', 'title', 'tag','is_prefix_in_title','title_is_in_query'\n",
    "            ,'prefix_word_len','title_word_len','prefix_is_question','prefix_is_network','query_score_mean','title_weight_similar'\n",
    "           ,'query_prediction_len','prefix_len','title_len','prefix_weight_similar']\n",
    "for feature in features:\n",
    "    a = data[feature].value_counts().to_dict()\n",
    "    data[feature+'_count'] = data[feature].apply(lambda x:a[x])\n",
    "    del a\n",
    "    gc.collect()\n",
    "    print(feature)\n",
    "print('part_1_finish')\n",
    "gc.collect()\n",
    "\n",
    "for  i in range(len(features)):\n",
    "    for j in range(i+1,len(features)):\n",
    "        new_feature = features[i]+'_'+features[j]\n",
    "        data[new_feature] = data[features[i]].astype(str) + '_' + data[features[j]].astype(str)\n",
    "        data[new_feature] = LabelEncoder().fit_transform(data[new_feature])\n",
    "        new_feature_count = new_feature + '_count'\n",
    "        a = data[new_feature].value_counts().to_dict()\n",
    "        data[new_feature_count] = data[new_feature].apply(lambda x : a[x])\n",
    "        gc.collect()\n",
    "        del a\n",
    "        print(i)\n",
    "print('part2_finish')\n",
    "gc.collect()\n",
    "\n",
    "pos_features = ['kmeans','title_weight_similar_bin', 'title_mean_similar_bin','title_max_similar_bin','prefix_title_sim_bin','query_prediction_len','prefix_len','title_len',\n",
    "                'title-prefix_len','prefix_word_len','title_word_len','title-prefix_word_len','prefix_max_similar_bin','prefix_mean_similar_bin',\n",
    "               'prefix_weight_similar_bin']\n",
    "for feature in pos_features:\n",
    "    train = data[(data['flag'] == 1)]\n",
    "    temp = train.groupby(feature,as_index=False)['label'].agg({feature+'_click_':'sum',feature+'_count':'count'})\n",
    "    data = pd.merge(data,temp,on=feature,how='left')\n",
    "    del train\n",
    "    del temp\n",
    "    gc.collect()\n",
    "    print(feature)\n",
    "print('part3_finish')\n",
    "\n",
    "features = ['prefix','title','tag']\n",
    "for feature in features:\n",
    "    data[feature] = LabelEncoder().fit_transform(data[feature])\n",
    "\n",
    "# data.to_csv(\"/home/ccit/tkhoon/liuyunEtlData/total_feature.csv\",index=False)\n",
    "print('run_co_feature_del')\n",
    "data = co_feature_del(data)\n",
    "gc.collect()\n",
    "train_X_data,vali_X_data,test_X_data,train_Y_data,vali_label = pre_data(data)\n",
    "print('run_lgb_test')\n",
    "predict,clf = lgb_test(train_X_data,vali_X_data,test_X_data,train_Y_data,vali_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_lgb_test\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[50]\ttraining's binary_logloss: 0.504337\tvalid_1's binary_logloss: 0.516818\n",
      "[100]\ttraining's binary_logloss: 0.485752\tvalid_1's binary_logloss: 0.501558\n",
      "[150]\ttraining's binary_logloss: 0.476202\tvalid_1's binary_logloss: 0.494058\n",
      "[200]\ttraining's binary_logloss: 0.469395\tvalid_1's binary_logloss: 0.489064\n",
      "[250]\ttraining's binary_logloss: 0.464152\tvalid_1's binary_logloss: 0.485088\n",
      "[300]\ttraining's binary_logloss: 0.459692\tvalid_1's binary_logloss: 0.481931\n",
      "[350]\ttraining's binary_logloss: 0.455959\tvalid_1's binary_logloss: 0.479275\n",
      "[400]\ttraining's binary_logloss: 0.452784\tvalid_1's binary_logloss: 0.477211\n",
      "[450]\ttraining's binary_logloss: 0.450178\tvalid_1's binary_logloss: 0.475447\n",
      "[500]\ttraining's binary_logloss: 0.447757\tvalid_1's binary_logloss: 0.473622\n",
      "[550]\ttraining's binary_logloss: 0.44562\tvalid_1's binary_logloss: 0.472192\n",
      "[600]\ttraining's binary_logloss: 0.44353\tvalid_1's binary_logloss: 0.470901\n",
      "[650]\ttraining's binary_logloss: 0.441682\tvalid_1's binary_logloss: 0.469675\n",
      "[700]\ttraining's binary_logloss: 0.43994\tvalid_1's binary_logloss: 0.468644\n",
      "[750]\ttraining's binary_logloss: 0.438121\tvalid_1's binary_logloss: 0.467573\n",
      "[800]\ttraining's binary_logloss: 0.436477\tvalid_1's binary_logloss: 0.466551\n",
      "[850]\ttraining's binary_logloss: 0.434873\tvalid_1's binary_logloss: 0.465508\n",
      "[900]\ttraining's binary_logloss: 0.433352\tvalid_1's binary_logloss: 0.46464\n",
      "[950]\ttraining's binary_logloss: 0.431929\tvalid_1's binary_logloss: 0.463729\n",
      "[1000]\ttraining's binary_logloss: 0.430599\tvalid_1's binary_logloss: 0.462965\n",
      "[1050]\ttraining's binary_logloss: 0.429311\tvalid_1's binary_logloss: 0.462229\n",
      "[1100]\ttraining's binary_logloss: 0.428033\tvalid_1's binary_logloss: 0.46153\n",
      "[1150]\ttraining's binary_logloss: 0.426868\tvalid_1's binary_logloss: 0.460923\n",
      "[1200]\ttraining's binary_logloss: 0.425622\tvalid_1's binary_logloss: 0.460121\n",
      "[1250]\ttraining's binary_logloss: 0.424396\tvalid_1's binary_logloss: 0.459375\n",
      "[1300]\ttraining's binary_logloss: 0.423225\tvalid_1's binary_logloss: 0.458796\n",
      "[1350]\ttraining's binary_logloss: 0.422098\tvalid_1's binary_logloss: 0.458134\n",
      "[1400]\ttraining's binary_logloss: 0.421112\tvalid_1's binary_logloss: 0.457605\n",
      "[1450]\ttraining's binary_logloss: 0.420162\tvalid_1's binary_logloss: 0.457233\n",
      "[1500]\ttraining's binary_logloss: 0.419224\tvalid_1's binary_logloss: 0.456841\n",
      "[1550]\ttraining's binary_logloss: 0.418203\tvalid_1's binary_logloss: 0.456386\n",
      "[1600]\ttraining's binary_logloss: 0.417282\tvalid_1's binary_logloss: 0.456006\n",
      "[1650]\ttraining's binary_logloss: 0.416418\tvalid_1's binary_logloss: 0.455574\n",
      "[1700]\ttraining's binary_logloss: 0.415458\tvalid_1's binary_logloss: 0.45524\n",
      "[1750]\ttraining's binary_logloss: 0.4145\tvalid_1's binary_logloss: 0.45466\n",
      "[1800]\ttraining's binary_logloss: 0.413533\tvalid_1's binary_logloss: 0.454189\n",
      "[1850]\ttraining's binary_logloss: 0.412617\tvalid_1's binary_logloss: 0.453756\n",
      "[1900]\ttraining's binary_logloss: 0.411836\tvalid_1's binary_logloss: 0.45343\n",
      "[1950]\ttraining's binary_logloss: 0.411012\tvalid_1's binary_logloss: 0.453089\n",
      "[2000]\ttraining's binary_logloss: 0.410207\tvalid_1's binary_logloss: 0.452758\n",
      "[2050]\ttraining's binary_logloss: 0.4094\tvalid_1's binary_logloss: 0.452372\n",
      "[2100]\ttraining's binary_logloss: 0.408627\tvalid_1's binary_logloss: 0.452037\n",
      "[2150]\ttraining's binary_logloss: 0.407893\tvalid_1's binary_logloss: 0.45184\n",
      "[2200]\ttraining's binary_logloss: 0.407187\tvalid_1's binary_logloss: 0.451567\n",
      "[2250]\ttraining's binary_logloss: 0.406506\tvalid_1's binary_logloss: 0.451286\n",
      "[2300]\ttraining's binary_logloss: 0.405796\tvalid_1's binary_logloss: 0.451009\n",
      "[2350]\ttraining's binary_logloss: 0.405151\tvalid_1's binary_logloss: 0.450796\n",
      "[2400]\ttraining's binary_logloss: 0.404482\tvalid_1's binary_logloss: 0.450531\n",
      "[2450]\ttraining's binary_logloss: 0.403824\tvalid_1's binary_logloss: 0.450251\n",
      "[2500]\ttraining's binary_logloss: 0.403102\tvalid_1's binary_logloss: 0.449885\n",
      "[2550]\ttraining's binary_logloss: 0.402358\tvalid_1's binary_logloss: 0.449522\n",
      "[2600]\ttraining's binary_logloss: 0.401782\tvalid_1's binary_logloss: 0.449359\n",
      "[2650]\ttraining's binary_logloss: 0.401174\tvalid_1's binary_logloss: 0.449172\n",
      "[2700]\ttraining's binary_logloss: 0.40055\tvalid_1's binary_logloss: 0.448875\n",
      "[2750]\ttraining's binary_logloss: 0.399937\tvalid_1's binary_logloss: 0.448671\n",
      "[2800]\ttraining's binary_logloss: 0.399308\tvalid_1's binary_logloss: 0.448487\n",
      "[2850]\ttraining's binary_logloss: 0.39868\tvalid_1's binary_logloss: 0.448197\n",
      "[2900]\ttraining's binary_logloss: 0.398108\tvalid_1's binary_logloss: 0.447959\n",
      "[2950]\ttraining's binary_logloss: 0.397489\tvalid_1's binary_logloss: 0.447778\n",
      "[3000]\ttraining's binary_logloss: 0.396869\tvalid_1's binary_logloss: 0.447522\n",
      "[3050]\ttraining's binary_logloss: 0.396332\tvalid_1's binary_logloss: 0.447359\n",
      "[3100]\ttraining's binary_logloss: 0.395773\tvalid_1's binary_logloss: 0.447167\n",
      "[3150]\ttraining's binary_logloss: 0.395199\tvalid_1's binary_logloss: 0.446985\n",
      "[3200]\ttraining's binary_logloss: 0.394651\tvalid_1's binary_logloss: 0.446814\n",
      "[3250]\ttraining's binary_logloss: 0.394097\tvalid_1's binary_logloss: 0.446536\n",
      "[3300]\ttraining's binary_logloss: 0.393522\tvalid_1's binary_logloss: 0.446324\n",
      "[3350]\ttraining's binary_logloss: 0.392953\tvalid_1's binary_logloss: 0.446125\n",
      "[3400]\ttraining's binary_logloss: 0.392454\tvalid_1's binary_logloss: 0.445909\n",
      "[3450]\ttraining's binary_logloss: 0.391977\tvalid_1's binary_logloss: 0.445686\n",
      "[3500]\ttraining's binary_logloss: 0.391442\tvalid_1's binary_logloss: 0.445497\n",
      "[3550]\ttraining's binary_logloss: 0.390925\tvalid_1's binary_logloss: 0.445342\n",
      "[3600]\ttraining's binary_logloss: 0.390381\tvalid_1's binary_logloss: 0.445151\n",
      "[3650]\ttraining's binary_logloss: 0.389939\tvalid_1's binary_logloss: 0.44506\n",
      "[3700]\ttraining's binary_logloss: 0.389406\tvalid_1's binary_logloss: 0.444883\n",
      "[3750]\ttraining's binary_logloss: 0.38889\tvalid_1's binary_logloss: 0.444694\n",
      "[3800]\ttraining's binary_logloss: 0.388393\tvalid_1's binary_logloss: 0.444496\n",
      "[3850]\ttraining's binary_logloss: 0.387959\tvalid_1's binary_logloss: 0.444406\n",
      "[3900]\ttraining's binary_logloss: 0.387523\tvalid_1's binary_logloss: 0.444281\n",
      "[3950]\ttraining's binary_logloss: 0.38704\tvalid_1's binary_logloss: 0.444131\n",
      "[4000]\ttraining's binary_logloss: 0.386571\tvalid_1's binary_logloss: 0.443982\n",
      "[4050]\ttraining's binary_logloss: 0.386063\tvalid_1's binary_logloss: 0.443736\n",
      "[4100]\ttraining's binary_logloss: 0.385588\tvalid_1's binary_logloss: 0.443576\n",
      "[4150]\ttraining's binary_logloss: 0.385094\tvalid_1's binary_logloss: 0.443387\n",
      "[4200]\ttraining's binary_logloss: 0.384619\tvalid_1's binary_logloss: 0.443228\n",
      "[4250]\ttraining's binary_logloss: 0.384191\tvalid_1's binary_logloss: 0.443095\n",
      "[4300]\ttraining's binary_logloss: 0.383733\tvalid_1's binary_logloss: 0.442963\n",
      "[4350]\ttraining's binary_logloss: 0.383285\tvalid_1's binary_logloss: 0.442854\n",
      "[4400]\ttraining's binary_logloss: 0.382864\tvalid_1's binary_logloss: 0.442688\n",
      "[4450]\ttraining's binary_logloss: 0.382436\tvalid_1's binary_logloss: 0.44252\n",
      "[4500]\ttraining's binary_logloss: 0.382024\tvalid_1's binary_logloss: 0.442387\n",
      "[4550]\ttraining's binary_logloss: 0.381575\tvalid_1's binary_logloss: 0.442233\n",
      "[4600]\ttraining's binary_logloss: 0.381169\tvalid_1's binary_logloss: 0.442072\n",
      "[4650]\ttraining's binary_logloss: 0.380758\tvalid_1's binary_logloss: 0.441927\n",
      "[4700]\ttraining's binary_logloss: 0.380344\tvalid_1's binary_logloss: 0.441816\n",
      "[4750]\ttraining's binary_logloss: 0.379939\tvalid_1's binary_logloss: 0.441729\n",
      "[4800]\ttraining's binary_logloss: 0.379548\tvalid_1's binary_logloss: 0.441606\n",
      "[4850]\ttraining's binary_logloss: 0.379162\tvalid_1's binary_logloss: 0.441471\n",
      "[4900]\ttraining's binary_logloss: 0.378757\tvalid_1's binary_logloss: 0.441329\n",
      "[4950]\ttraining's binary_logloss: 0.378381\tvalid_1's binary_logloss: 0.441188\n",
      "[5000]\ttraining's binary_logloss: 0.37799\tvalid_1's binary_logloss: 0.441109\n",
      "[5050]\ttraining's binary_logloss: 0.377658\tvalid_1's binary_logloss: 0.441031\n",
      "[5100]\ttraining's binary_logloss: 0.377272\tvalid_1's binary_logloss: 0.440893\n",
      "[5150]\ttraining's binary_logloss: 0.376894\tvalid_1's binary_logloss: 0.440754\n",
      "[5200]\ttraining's binary_logloss: 0.376507\tvalid_1's binary_logloss: 0.440691\n",
      "[5250]\ttraining's binary_logloss: 0.37612\tvalid_1's binary_logloss: 0.440586\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5300]\ttraining's binary_logloss: 0.375745\tvalid_1's binary_logloss: 0.440506\n",
      "[5350]\ttraining's binary_logloss: 0.375365\tvalid_1's binary_logloss: 0.440392\n",
      "[5400]\ttraining's binary_logloss: 0.374982\tvalid_1's binary_logloss: 0.440281\n",
      "[5450]\ttraining's binary_logloss: 0.374641\tvalid_1's binary_logloss: 0.440218\n",
      "[5500]\ttraining's binary_logloss: 0.374255\tvalid_1's binary_logloss: 0.440113\n",
      "[5550]\ttraining's binary_logloss: 0.373892\tvalid_1's binary_logloss: 0.439975\n",
      "[5600]\ttraining's binary_logloss: 0.373529\tvalid_1's binary_logloss: 0.439927\n",
      "[5650]\ttraining's binary_logloss: 0.373159\tvalid_1's binary_logloss: 0.439879\n",
      "[5700]\ttraining's binary_logloss: 0.372826\tvalid_1's binary_logloss: 0.439754\n",
      "[5750]\ttraining's binary_logloss: 0.372457\tvalid_1's binary_logloss: 0.439692\n",
      "[5800]\ttraining's binary_logloss: 0.372136\tvalid_1's binary_logloss: 0.439686\n",
      "[5850]\ttraining's binary_logloss: 0.371793\tvalid_1's binary_logloss: 0.439575\n",
      "[5900]\ttraining's binary_logloss: 0.371488\tvalid_1's binary_logloss: 0.439511\n",
      "[5950]\ttraining's binary_logloss: 0.37115\tvalid_1's binary_logloss: 0.43939\n",
      "[6000]\ttraining's binary_logloss: 0.370824\tvalid_1's binary_logloss: 0.439309\n",
      "[6050]\ttraining's binary_logloss: 0.370481\tvalid_1's binary_logloss: 0.439217\n",
      "[6100]\ttraining's binary_logloss: 0.370142\tvalid_1's binary_logloss: 0.439143\n",
      "[6150]\ttraining's binary_logloss: 0.369804\tvalid_1's binary_logloss: 0.439065\n",
      "[6200]\ttraining's binary_logloss: 0.369513\tvalid_1's binary_logloss: 0.439074\n",
      "[6250]\ttraining's binary_logloss: 0.36921\tvalid_1's binary_logloss: 0.439\n",
      "[6300]\ttraining's binary_logloss: 0.36887\tvalid_1's binary_logloss: 0.438952\n",
      "[6350]\ttraining's binary_logloss: 0.368549\tvalid_1's binary_logloss: 0.438855\n",
      "[6400]\ttraining's binary_logloss: 0.368231\tvalid_1's binary_logloss: 0.438731\n",
      "[6450]\ttraining's binary_logloss: 0.367896\tvalid_1's binary_logloss: 0.438673\n",
      "[6500]\ttraining's binary_logloss: 0.367602\tvalid_1's binary_logloss: 0.438632\n",
      "[6550]\ttraining's binary_logloss: 0.367291\tvalid_1's binary_logloss: 0.438556\n",
      "[6600]\ttraining's binary_logloss: 0.366995\tvalid_1's binary_logloss: 0.438458\n",
      "[6650]\ttraining's binary_logloss: 0.366684\tvalid_1's binary_logloss: 0.438386\n",
      "[6700]\ttraining's binary_logloss: 0.366393\tvalid_1's binary_logloss: 0.438314\n",
      "[6750]\ttraining's binary_logloss: 0.366128\tvalid_1's binary_logloss: 0.43827\n",
      "[6800]\ttraining's binary_logloss: 0.365851\tvalid_1's binary_logloss: 0.438247\n",
      "[6850]\ttraining's binary_logloss: 0.365537\tvalid_1's binary_logloss: 0.43816\n",
      "[6900]\ttraining's binary_logloss: 0.365248\tvalid_1's binary_logloss: 0.438117\n",
      "[6950]\ttraining's binary_logloss: 0.364936\tvalid_1's binary_logloss: 0.438061\n",
      "[7000]\ttraining's binary_logloss: 0.36466\tvalid_1's binary_logloss: 0.438019\n",
      "[7050]\ttraining's binary_logloss: 0.364377\tvalid_1's binary_logloss: 0.437973\n",
      "[7100]\ttraining's binary_logloss: 0.364114\tvalid_1's binary_logloss: 0.437918\n",
      "[7150]\ttraining's binary_logloss: 0.363834\tvalid_1's binary_logloss: 0.437845\n",
      "[7200]\ttraining's binary_logloss: 0.363565\tvalid_1's binary_logloss: 0.437831\n",
      "[7250]\ttraining's binary_logloss: 0.363298\tvalid_1's binary_logloss: 0.43771\n",
      "[7300]\ttraining's binary_logloss: 0.363018\tvalid_1's binary_logloss: 0.437632\n",
      "[7350]\ttraining's binary_logloss: 0.362755\tvalid_1's binary_logloss: 0.437511\n",
      "[7400]\ttraining's binary_logloss: 0.362475\tvalid_1's binary_logloss: 0.437523\n",
      "[7450]\ttraining's binary_logloss: 0.362212\tvalid_1's binary_logloss: 0.437474\n",
      "[7500]\ttraining's binary_logloss: 0.361912\tvalid_1's binary_logloss: 0.437394\n",
      "[7550]\ttraining's binary_logloss: 0.3617\tvalid_1's binary_logloss: 0.437339\n",
      "[7600]\ttraining's binary_logloss: 0.361428\tvalid_1's binary_logloss: 0.437293\n",
      "[7650]\ttraining's binary_logloss: 0.361167\tvalid_1's binary_logloss: 0.437275\n",
      "[7700]\ttraining's binary_logloss: 0.360883\tvalid_1's binary_logloss: 0.437233\n",
      "[7750]\ttraining's binary_logloss: 0.360626\tvalid_1's binary_logloss: 0.437144\n",
      "[7800]\ttraining's binary_logloss: 0.360358\tvalid_1's binary_logloss: 0.437155\n",
      "[7850]\ttraining's binary_logloss: 0.360122\tvalid_1's binary_logloss: 0.437112\n",
      "[7900]\ttraining's binary_logloss: 0.359858\tvalid_1's binary_logloss: 0.437038\n",
      "[7950]\ttraining's binary_logloss: 0.359603\tvalid_1's binary_logloss: 0.436983\n",
      "[8000]\ttraining's binary_logloss: 0.359367\tvalid_1's binary_logloss: 0.436948\n",
      "[8050]\ttraining's binary_logloss: 0.359129\tvalid_1's binary_logloss: 0.436882\n",
      "[8100]\ttraining's binary_logloss: 0.358887\tvalid_1's binary_logloss: 0.436884\n",
      "[8150]\ttraining's binary_logloss: 0.358639\tvalid_1's binary_logloss: 0.436856\n",
      "[8200]\ttraining's binary_logloss: 0.358407\tvalid_1's binary_logloss: 0.436799\n",
      "[8250]\ttraining's binary_logloss: 0.358159\tvalid_1's binary_logloss: 0.436787\n",
      "[8300]\ttraining's binary_logloss: 0.357901\tvalid_1's binary_logloss: 0.436734\n",
      "[8350]\ttraining's binary_logloss: 0.357651\tvalid_1's binary_logloss: 0.436679\n",
      "[8400]\ttraining's binary_logloss: 0.35738\tvalid_1's binary_logloss: 0.436669\n",
      "[8450]\ttraining's binary_logloss: 0.357135\tvalid_1's binary_logloss: 0.436665\n",
      "[8500]\ttraining's binary_logloss: 0.356901\tvalid_1's binary_logloss: 0.436602\n",
      "[8550]\ttraining's binary_logloss: 0.356656\tvalid_1's binary_logloss: 0.436542\n",
      "[8600]\ttraining's binary_logloss: 0.356438\tvalid_1's binary_logloss: 0.436531\n",
      "[8650]\ttraining's binary_logloss: 0.356223\tvalid_1's binary_logloss: 0.436511\n",
      "[8700]\ttraining's binary_logloss: 0.35599\tvalid_1's binary_logloss: 0.436499\n",
      "Early stopping, best iteration is:\n",
      "[8640]\ttraining's binary_logloss: 0.356258\tvalid_1's binary_logloss: 0.436491\n",
      "最大f1为 0.7387516092861\n",
      "此时阈值为: 0.39900000000000013\n",
      "best_f1: 0.7387516092861\n",
      "best_thr: 0.39900000000000013\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "import Levenshtein\n",
    "from gensim import matutils\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import warnings\n",
    "import os\n",
    "import jieba\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from operator import itemgetter\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold as skf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import word2vec\n",
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "from sklearn.metrics import f1_score\n",
    "import gc\n",
    "\n",
    "def kmeans(data):\n",
    "    from sklearn.cluster import KMeans\n",
    "    features = ['prefix','title','tag']\n",
    "    for feature in features:\n",
    "        data[feature] = LabelEncoder().fit_transform(data[feature])\n",
    "    columns = ['query_prediction', 'label', 'flag', 'is_prefix_contains_upper_english', 'item_dict','query_word','query_score']\n",
    "    data_ = data.drop(columns,axis=1)\n",
    "    kmeans = KMeans(n_clusters=25,init='k-means++',max_iter=300,verbose=1,n_jobs=-1)\n",
    "    a = kmeans.fit_predict(data_)\n",
    "    data['kmeans'] = a\n",
    "    del data_\n",
    "    return data\n",
    "\n",
    "def co_feature_del(data):\n",
    "    threshold = 0.99\n",
    "    # Absolute value correlation matrix\n",
    "    corr_matrix = data.corr().abs()\n",
    "    # corr_matrix.head()\n",
    "    upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n",
    "    # upper.head()\n",
    "    to_drop = [column for column in upper.columns if any(upper[column] > threshold)]\n",
    "    print('There are %d columns to remove.' % (len(to_drop)))\n",
    "    data.drop(to_drop, axis=1, inplace=True)\n",
    "    \n",
    "    del upper\n",
    "    del to_drop\n",
    "    del corr_matrix\n",
    "    return data\n",
    "\n",
    "def pre_data(data):\n",
    "    # 先看一下，没有加入作为特征得\n",
    "    train = data[data['flag'] == 1]\n",
    "    vali = data[data['flag'] == 2]\n",
    "    test = data[data['flag'] == 3]\n",
    "\n",
    "    train_X_data = train.drop(['query_prediction', 'label', 'flag', 'is_prefix_contains_upper_english', 'item_dict','query_word','query_score'],\n",
    "                              axis=1)\n",
    "    vali_X_data = vali.drop(['query_prediction', 'label', 'flag', 'is_prefix_contains_upper_english', 'item_dict','query_word','query_score'],\n",
    "                            axis=1)\n",
    "    test_X_data = test.drop(['query_prediction', 'label', 'flag', 'is_prefix_contains_upper_english', 'item_dict','query_word','query_score'],\n",
    "                            axis=1)\n",
    "    train_Y_data = train['label']\n",
    "    vali_label = vali['label']\n",
    "    \n",
    "    del train\n",
    "    del vali\n",
    "    del test\n",
    "    del data\n",
    "    return train_X_data,vali_X_data,test_X_data,train_Y_data,vali_label\n",
    "\n",
    "def lgb_test(train_X_data,vali_X_data,train_Y_data,vali_label):\n",
    "\n",
    "    predict = []\n",
    "    clf = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt', subsample=1, colsample_bytree=1,\n",
    "    max_depth=-1, n_estimators=10000, objective='binary',min_child_weight = 10,\n",
    "    subsample_freq=1, num_leaves=127, reg_alpha=0,reg_lambda = 1.3,\n",
    "    random_state=2018, n_jobs=-1, learning_rate=0.1)\n",
    "\n",
    "    clf.fit(train_X_data, train_Y_data,eval_set=[(train_X_data,train_Y_data),(vali_X_data,vali_label)], eval_metric='logloss',verbose = 50, early_stopping_rounds=100)\n",
    "    predict = clf.predict_proba(vali_X_data,num_iteration=clf.best_iteration_)\n",
    "    return predict,clf\n",
    "\n",
    "def find_best_thr(predict,vali_label):\n",
    "    max = 0.0\n",
    "    max_i =0.0\n",
    "    predict = pd.DataFrame(predict)\n",
    "    predict = predict[1]\n",
    "    predict = pd.DataFrame(predict)\n",
    "    for i in np.arange(0.25, 0.4500, 0.001):\n",
    "        f1 = f1_score(vali_label, predict[1].map(lambda x: 0 if x < i else 1))\n",
    "        if (f1 > max):\n",
    "            max = f1_score(vali_label, predict[1].map(lambda x: 0 if x <= i else 1))\n",
    "            max_i = i\n",
    "    print('最大f1为', max)\n",
    "    print('此时阈值为:', max_i)\n",
    "\n",
    "    return max,max_i\n",
    "\n",
    "data = pd.read_csv(\"/home/ccit/tkhoon/liuyunEtlData/feature.csv\")\n",
    "data['prefix'] = data['prefix'].astype(str)\n",
    "data['title'] = data['title'].astype(str)\n",
    "data['prefix_max_similar'] = data['prefix_max_similar'].fillna(data['prefix_max_similar'].mean())\n",
    "data['prefix_title_sim_bin'] = pd.qcut(data['prefix_title_sim'],8)\n",
    "data['prefix_title_sim_bin'] = pd.factorize(data['prefix_title_sim_bin'])[0]\n",
    "\n",
    "data['title_weight_similar_bin'] = pd.qcut(data['title_weight_similar'],10)\n",
    "data['title_weight_similar_bin'] = pd.factorize(data['title_weight_similar_bin'])[0]\n",
    "\n",
    "data['title_mean_similar_bin'] = pd.qcut(data['title_mean_similar'],5)\n",
    "data['title_mean_similar_bin'] = pd.factorize(data['title_mean_similar_bin'])[0]\n",
    "\n",
    "data['title_max_similar_bin'] = pd.qcut(data['title_max_similar'],5)\n",
    "data['title_max_similar_bin']  = pd.factorize(data['title_max_similar_bin'])[0]\n",
    "\n",
    "data['prefix_weight_similar_bin'] = pd.qcut(data['prefix_weight_similar'],10)\n",
    "data['prefix_weight_similar_bin'] = pd.factorize(data['prefix_weight_similar_bin'])[0]\n",
    "\n",
    "data['prefix_mean_similar_bin'] = pd.qcut(data['prefix_mean_similar'],5)\n",
    "data['prefix_mean_similar_bin'] = pd.factorize(data['prefix_mean_similar_bin'])[0]\n",
    "\n",
    "data['prefix_max_similar_bin'] = pd.qcut(data['prefix_max_similar'],3)\n",
    "data['prefix_max_similar_bin']  = pd.factorize(data['prefix_max_similar_bin'])[0]\n",
    "\n",
    "print('run_kmeans')\n",
    "data = kmeans(data)\n",
    "print('run_feature')\n",
    "gc.collect()\n",
    "\n",
    "features = ['kmeans','prefix', 'title', 'tag','is_prefix_in_title','title_is_in_query'\n",
    "            ,'prefix_word_len','title_word_len','prefix_is_question',\n",
    "            'prefix_is_network','query_score_mean','title_weight_similar']\n",
    "\n",
    "for feature in features:\n",
    "    a = data[feature].value_counts().to_dict()\n",
    "    data[feature+'_count'] = data[feature].apply(lambda x:a[x])\n",
    "    del a\n",
    "    gc.collect()\n",
    "    print(feature)\n",
    "print('part_1_finish')\n",
    "gc.collect()\n",
    "\n",
    "for  i in range(len(features)):\n",
    "    for j in range(i+1,len(features)):\n",
    "        new_feature = features[i]+'_'+features[j]\n",
    "        data[new_feature] = data[features[i]].astype(str) + '_' + data[features[j]].astype(str)\n",
    "        data[new_feature] = LabelEncoder().fit_transform(data[new_feature])\n",
    "        new_feature_count = new_feature + '_count'\n",
    "        a = data[new_feature].value_counts().to_dict()\n",
    "        data[new_feature_count] = data[new_feature].apply(lambda x : a[x])\n",
    "        gc.collect()\n",
    "        del a\n",
    "        print(i)\n",
    "print('part2_finish')\n",
    "gc.collect()\n",
    "\n",
    "pos_features = ['kmeans','title_weight_similar_bin', 'title_mean_similar_bin','title_max_similar_bin','prefix_title_sim_bin','query_prediction_len','prefix_len','title_len',\n",
    "                'title-prefix_len','prefix_word_len','title_word_len','title-prefix_word_len','prefix_max_similar_bin','prefix_mean_similar_bin',\n",
    "               'prefix_weight_similar_bin']\n",
    "for feature in pos_features:\n",
    "    train = data[(data['flag'] == 1)]\n",
    "    temp = train.groupby(feature,as_index=False)['label'].agg({feature+'_click_':'sum'})\n",
    "#     temp[feature+'_ctr_'] = temp[feature+'_click_'] / (temp[feature+'_count'] + 5)\n",
    "    data = pd.merge(data,temp,on=feature,how='left')\n",
    "    del train\n",
    "    del temp\n",
    "    gc.collect()\n",
    "    print(feature)\n",
    "print('part3_finish')\n",
    "\n",
    "features = ['prefix','title','tag']\n",
    "for feature in features:\n",
    "    data[feature] = LabelEncoder().fit_transform(data[feature])\n",
    "\n",
    "# data.to_csv(\"/home/ccit/tkhoon/liuyunEtlData/total_feature.csv\",index=False)\n",
    "print('run_co_feature_del')\n",
    "data = co_feature_del(data)\n",
    "gc.collect()\n",
    "train_X_data,vali_X_data,test_X_data,train_Y_data,vali_label = pre_data(data)\n",
    "print('run_lgb_test')\n",
    "predict,clf = lgb_test(train_X_data,vali_X_data,train_Y_data,vali_label)\n",
    "\n",
    "best_f1,best_thr = find_best_thr(predict,vali_label)\n",
    "\n",
    "print('best_f1:',best_f1)\n",
    "print('best_thr:',best_thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.DataFrame(clf.predict_proba(test_X_data,num_iteration=clf.best_iteration_))[1]\n",
    "submit = submit.map(lambda x: 0 if x <=  0.39900000000000013 else 1)\n",
    "submit.to_csv('/home/ccit/tkhoon/liuyunEtlData/submit7387.csv',index=False,encoding='utf-8',header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5kflod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kflod: 0\n",
      "Training until validation scores don't improve for 150 rounds.\n",
      "[50]\ttraining's binary_logloss: 0.504774\tvalid_1's binary_logloss: 0.504718\n",
      "[100]\ttraining's binary_logloss: 0.486408\tvalid_1's binary_logloss: 0.486919\n",
      "[150]\ttraining's binary_logloss: 0.476188\tvalid_1's binary_logloss: 0.477379\n",
      "[200]\ttraining's binary_logloss: 0.469549\tvalid_1's binary_logloss: 0.471411\n",
      "[250]\ttraining's binary_logloss: 0.464549\tvalid_1's binary_logloss: 0.467065\n",
      "[300]\ttraining's binary_logloss: 0.460237\tvalid_1's binary_logloss: 0.463463\n",
      "[350]\ttraining's binary_logloss: 0.456288\tvalid_1's binary_logloss: 0.46019\n",
      "[400]\ttraining's binary_logloss: 0.452888\tvalid_1's binary_logloss: 0.457483\n",
      "[450]\ttraining's binary_logloss: 0.45012\tvalid_1's binary_logloss: 0.45536\n",
      "[500]\ttraining's binary_logloss: 0.447502\tvalid_1's binary_logloss: 0.453377\n",
      "[550]\ttraining's binary_logloss: 0.445085\tvalid_1's binary_logloss: 0.451574\n",
      "[600]\ttraining's binary_logloss: 0.442833\tvalid_1's binary_logloss: 0.450014\n",
      "[650]\ttraining's binary_logloss: 0.440897\tvalid_1's binary_logloss: 0.448755\n",
      "[700]\ttraining's binary_logloss: 0.43902\tvalid_1's binary_logloss: 0.447517\n",
      "[750]\ttraining's binary_logloss: 0.437401\tvalid_1's binary_logloss: 0.446583\n",
      "[800]\ttraining's binary_logloss: 0.435689\tvalid_1's binary_logloss: 0.445528\n",
      "[850]\ttraining's binary_logloss: 0.434061\tvalid_1's binary_logloss: 0.44455\n",
      "[900]\ttraining's binary_logloss: 0.432523\tvalid_1's binary_logloss: 0.443612\n",
      "[950]\ttraining's binary_logloss: 0.430994\tvalid_1's binary_logloss: 0.442678\n",
      "[1000]\ttraining's binary_logloss: 0.429555\tvalid_1's binary_logloss: 0.441907\n",
      "[1050]\ttraining's binary_logloss: 0.428278\tvalid_1's binary_logloss: 0.441275\n",
      "[1100]\ttraining's binary_logloss: 0.426946\tvalid_1's binary_logloss: 0.440591\n",
      "[1150]\ttraining's binary_logloss: 0.425604\tvalid_1's binary_logloss: 0.439869\n",
      "[1200]\ttraining's binary_logloss: 0.424379\tvalid_1's binary_logloss: 0.439267\n",
      "[1250]\ttraining's binary_logloss: 0.423187\tvalid_1's binary_logloss: 0.438714\n",
      "[1300]\ttraining's binary_logloss: 0.421893\tvalid_1's binary_logloss: 0.438026\n",
      "[1350]\ttraining's binary_logloss: 0.420761\tvalid_1's binary_logloss: 0.437482\n",
      "[1400]\ttraining's binary_logloss: 0.419723\tvalid_1's binary_logloss: 0.437057\n",
      "[1450]\ttraining's binary_logloss: 0.418572\tvalid_1's binary_logloss: 0.436467\n",
      "[1500]\ttraining's binary_logloss: 0.41757\tvalid_1's binary_logloss: 0.436003\n",
      "[1550]\ttraining's binary_logloss: 0.416531\tvalid_1's binary_logloss: 0.435567\n",
      "[1600]\ttraining's binary_logloss: 0.415487\tvalid_1's binary_logloss: 0.435115\n",
      "[1650]\ttraining's binary_logloss: 0.414465\tvalid_1's binary_logloss: 0.434688\n",
      "[1700]\ttraining's binary_logloss: 0.413428\tvalid_1's binary_logloss: 0.434254\n",
      "[1750]\ttraining's binary_logloss: 0.412458\tvalid_1's binary_logloss: 0.433844\n",
      "[1800]\ttraining's binary_logloss: 0.411505\tvalid_1's binary_logloss: 0.433414\n",
      "[1850]\ttraining's binary_logloss: 0.410586\tvalid_1's binary_logloss: 0.433073\n",
      "[1900]\ttraining's binary_logloss: 0.409651\tvalid_1's binary_logloss: 0.432704\n",
      "[1950]\ttraining's binary_logloss: 0.40874\tvalid_1's binary_logloss: 0.432328\n",
      "[2000]\ttraining's binary_logloss: 0.407894\tvalid_1's binary_logloss: 0.432051\n",
      "[2050]\ttraining's binary_logloss: 0.407097\tvalid_1's binary_logloss: 0.431771\n",
      "[2100]\ttraining's binary_logloss: 0.406287\tvalid_1's binary_logloss: 0.431471\n",
      "[2150]\ttraining's binary_logloss: 0.405446\tvalid_1's binary_logloss: 0.431214\n",
      "[2200]\ttraining's binary_logloss: 0.404633\tvalid_1's binary_logloss: 0.430947\n",
      "[2250]\ttraining's binary_logloss: 0.403811\tvalid_1's binary_logloss: 0.430683\n",
      "[2300]\ttraining's binary_logloss: 0.402972\tvalid_1's binary_logloss: 0.430373\n",
      "[2350]\ttraining's binary_logloss: 0.402162\tvalid_1's binary_logloss: 0.430112\n",
      "[2400]\ttraining's binary_logloss: 0.401371\tvalid_1's binary_logloss: 0.429904\n",
      "[2450]\ttraining's binary_logloss: 0.400629\tvalid_1's binary_logloss: 0.429654\n",
      "[2500]\ttraining's binary_logloss: 0.399907\tvalid_1's binary_logloss: 0.429411\n",
      "[2550]\ttraining's binary_logloss: 0.399095\tvalid_1's binary_logloss: 0.429169\n",
      "[2600]\ttraining's binary_logloss: 0.398358\tvalid_1's binary_logloss: 0.428956\n",
      "[2650]\ttraining's binary_logloss: 0.39767\tvalid_1's binary_logloss: 0.428787\n",
      "[2700]\ttraining's binary_logloss: 0.396985\tvalid_1's binary_logloss: 0.428594\n",
      "[2750]\ttraining's binary_logloss: 0.396325\tvalid_1's binary_logloss: 0.428398\n",
      "[2800]\ttraining's binary_logloss: 0.395669\tvalid_1's binary_logloss: 0.428228\n",
      "[2850]\ttraining's binary_logloss: 0.395032\tvalid_1's binary_logloss: 0.428037\n",
      "[2900]\ttraining's binary_logloss: 0.394303\tvalid_1's binary_logloss: 0.427793\n",
      "[2950]\ttraining's binary_logloss: 0.393612\tvalid_1's binary_logloss: 0.427576\n",
      "[3000]\ttraining's binary_logloss: 0.392956\tvalid_1's binary_logloss: 0.427419\n",
      "[3050]\ttraining's binary_logloss: 0.39232\tvalid_1's binary_logloss: 0.427238\n",
      "[3100]\ttraining's binary_logloss: 0.3917\tvalid_1's binary_logloss: 0.42709\n",
      "[3150]\ttraining's binary_logloss: 0.391103\tvalid_1's binary_logloss: 0.426931\n",
      "[3200]\ttraining's binary_logloss: 0.390466\tvalid_1's binary_logloss: 0.42674\n",
      "[3250]\ttraining's binary_logloss: 0.389839\tvalid_1's binary_logloss: 0.426596\n",
      "[3300]\ttraining's binary_logloss: 0.389228\tvalid_1's binary_logloss: 0.426484\n",
      "[3350]\ttraining's binary_logloss: 0.388631\tvalid_1's binary_logloss: 0.426354\n",
      "[3400]\ttraining's binary_logloss: 0.388083\tvalid_1's binary_logloss: 0.426257\n",
      "[3450]\ttraining's binary_logloss: 0.3875\tvalid_1's binary_logloss: 0.426127\n",
      "[3500]\ttraining's binary_logloss: 0.386955\tvalid_1's binary_logloss: 0.426018\n",
      "[3550]\ttraining's binary_logloss: 0.386413\tvalid_1's binary_logloss: 0.425901\n",
      "[3600]\ttraining's binary_logloss: 0.385881\tvalid_1's binary_logloss: 0.425783\n",
      "[3650]\ttraining's binary_logloss: 0.385259\tvalid_1's binary_logloss: 0.425642\n",
      "[3700]\ttraining's binary_logloss: 0.384744\tvalid_1's binary_logloss: 0.425548\n",
      "[3750]\ttraining's binary_logloss: 0.384213\tvalid_1's binary_logloss: 0.425435\n",
      "[3800]\ttraining's binary_logloss: 0.3837\tvalid_1's binary_logloss: 0.425329\n",
      "[3850]\ttraining's binary_logloss: 0.38314\tvalid_1's binary_logloss: 0.425227\n",
      "[3900]\ttraining's binary_logloss: 0.382597\tvalid_1's binary_logloss: 0.425113\n",
      "[3950]\ttraining's binary_logloss: 0.382044\tvalid_1's binary_logloss: 0.425019\n",
      "[4000]\ttraining's binary_logloss: 0.381508\tvalid_1's binary_logloss: 0.424933\n",
      "[4050]\ttraining's binary_logloss: 0.380951\tvalid_1's binary_logloss: 0.424806\n",
      "[4100]\ttraining's binary_logloss: 0.380429\tvalid_1's binary_logloss: 0.424682\n",
      "[4150]\ttraining's binary_logloss: 0.37991\tvalid_1's binary_logloss: 0.424572\n",
      "[4200]\ttraining's binary_logloss: 0.37941\tvalid_1's binary_logloss: 0.424482\n",
      "[4250]\ttraining's binary_logloss: 0.378915\tvalid_1's binary_logloss: 0.424397\n",
      "[4300]\ttraining's binary_logloss: 0.378425\tvalid_1's binary_logloss: 0.424308\n",
      "[4350]\ttraining's binary_logloss: 0.377905\tvalid_1's binary_logloss: 0.424194\n",
      "[4400]\ttraining's binary_logloss: 0.377451\tvalid_1's binary_logloss: 0.424143\n",
      "[4450]\ttraining's binary_logloss: 0.377004\tvalid_1's binary_logloss: 0.424063\n",
      "[4500]\ttraining's binary_logloss: 0.376558\tvalid_1's binary_logloss: 0.423998\n",
      "[4550]\ttraining's binary_logloss: 0.376103\tvalid_1's binary_logloss: 0.42393\n",
      "[4600]\ttraining's binary_logloss: 0.37562\tvalid_1's binary_logloss: 0.423847\n",
      "[4650]\ttraining's binary_logloss: 0.375177\tvalid_1's binary_logloss: 0.423779\n",
      "[4700]\ttraining's binary_logloss: 0.374676\tvalid_1's binary_logloss: 0.423704\n",
      "[4750]\ttraining's binary_logloss: 0.374265\tvalid_1's binary_logloss: 0.423641\n",
      "[4800]\ttraining's binary_logloss: 0.373823\tvalid_1's binary_logloss: 0.423603\n",
      "[4850]\ttraining's binary_logloss: 0.373395\tvalid_1's binary_logloss: 0.423544\n",
      "[4900]\ttraining's binary_logloss: 0.37298\tvalid_1's binary_logloss: 0.423483\n",
      "[4950]\ttraining's binary_logloss: 0.372544\tvalid_1's binary_logloss: 0.423428\n",
      "[5000]\ttraining's binary_logloss: 0.372113\tvalid_1's binary_logloss: 0.423379\n",
      "[5050]\ttraining's binary_logloss: 0.371666\tvalid_1's binary_logloss: 0.423329\n",
      "[5100]\ttraining's binary_logloss: 0.371233\tvalid_1's binary_logloss: 0.423269\n",
      "[5150]\ttraining's binary_logloss: 0.370801\tvalid_1's binary_logloss: 0.423216\n",
      "[5200]\ttraining's binary_logloss: 0.370407\tvalid_1's binary_logloss: 0.423183\n",
      "[5250]\ttraining's binary_logloss: 0.369994\tvalid_1's binary_logloss: 0.423146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5300]\ttraining's binary_logloss: 0.369608\tvalid_1's binary_logloss: 0.4231\n",
      "[5350]\ttraining's binary_logloss: 0.369219\tvalid_1's binary_logloss: 0.423077\n",
      "[5400]\ttraining's binary_logloss: 0.368802\tvalid_1's binary_logloss: 0.423034\n",
      "[5450]\ttraining's binary_logloss: 0.36838\tvalid_1's binary_logloss: 0.422981\n",
      "[5500]\ttraining's binary_logloss: 0.367969\tvalid_1's binary_logloss: 0.422932\n",
      "[5550]\ttraining's binary_logloss: 0.36758\tvalid_1's binary_logloss: 0.422916\n",
      "[5600]\ttraining's binary_logloss: 0.367155\tvalid_1's binary_logloss: 0.422875\n",
      "[5650]\ttraining's binary_logloss: 0.366766\tvalid_1's binary_logloss: 0.422835\n",
      "[5700]\ttraining's binary_logloss: 0.366379\tvalid_1's binary_logloss: 0.422822\n",
      "[5750]\ttraining's binary_logloss: 0.365978\tvalid_1's binary_logloss: 0.422781\n",
      "[5800]\ttraining's binary_logloss: 0.365566\tvalid_1's binary_logloss: 0.42271\n",
      "[5850]\ttraining's binary_logloss: 0.365232\tvalid_1's binary_logloss: 0.422682\n",
      "[5900]\ttraining's binary_logloss: 0.36491\tvalid_1's binary_logloss: 0.42267\n",
      "[5950]\ttraining's binary_logloss: 0.364555\tvalid_1's binary_logloss: 0.42265\n",
      "[6000]\ttraining's binary_logloss: 0.364216\tvalid_1's binary_logloss: 0.422651\n",
      "[6050]\ttraining's binary_logloss: 0.363878\tvalid_1's binary_logloss: 0.422624\n",
      "[6100]\ttraining's binary_logloss: 0.363531\tvalid_1's binary_logloss: 0.42261\n",
      "[6150]\ttraining's binary_logloss: 0.363224\tvalid_1's binary_logloss: 0.422602\n",
      "[6200]\ttraining's binary_logloss: 0.362879\tvalid_1's binary_logloss: 0.422575\n",
      "[6250]\ttraining's binary_logloss: 0.362539\tvalid_1's binary_logloss: 0.422557\n",
      "[6300]\ttraining's binary_logloss: 0.362215\tvalid_1's binary_logloss: 0.422542\n",
      "[6350]\ttraining's binary_logloss: 0.361851\tvalid_1's binary_logloss: 0.422518\n",
      "[6400]\ttraining's binary_logloss: 0.361533\tvalid_1's binary_logloss: 0.422509\n",
      "[6450]\ttraining's binary_logloss: 0.361229\tvalid_1's binary_logloss: 0.422501\n",
      "[6500]\ttraining's binary_logloss: 0.360896\tvalid_1's binary_logloss: 0.422494\n",
      "[6550]\ttraining's binary_logloss: 0.360555\tvalid_1's binary_logloss: 0.422486\n",
      "[6600]\ttraining's binary_logloss: 0.360234\tvalid_1's binary_logloss: 0.422487\n",
      "[6650]\ttraining's binary_logloss: 0.35991\tvalid_1's binary_logloss: 0.422478\n",
      "[6700]\ttraining's binary_logloss: 0.359599\tvalid_1's binary_logloss: 0.422477\n",
      "[6750]\ttraining's binary_logloss: 0.359285\tvalid_1's binary_logloss: 0.422476\n",
      "[6800]\ttraining's binary_logloss: 0.358922\tvalid_1's binary_logloss: 0.422465\n",
      "[6850]\ttraining's binary_logloss: 0.358635\tvalid_1's binary_logloss: 0.422472\n",
      "[6900]\ttraining's binary_logloss: 0.358315\tvalid_1's binary_logloss: 0.422444\n",
      "[6950]\ttraining's binary_logloss: 0.357956\tvalid_1's binary_logloss: 0.422414\n",
      "[7000]\ttraining's binary_logloss: 0.357634\tvalid_1's binary_logloss: 0.422423\n",
      "[7050]\ttraining's binary_logloss: 0.35733\tvalid_1's binary_logloss: 0.422415\n",
      "[7100]\ttraining's binary_logloss: 0.357032\tvalid_1's binary_logloss: 0.422416\n",
      "Early stopping, best iteration is:\n",
      "[6959]\ttraining's binary_logloss: 0.35789\tvalid_1's binary_logloss: 0.422407\n",
      "最大f1为 0.8063624628553112\n",
      "此时阈值为: 0.41900000000000015\n",
      "kflod: 1\n",
      "Training until validation scores don't improve for 150 rounds.\n",
      "[50]\ttraining's binary_logloss: 0.504671\tvalid_1's binary_logloss: 0.505112\n",
      "[100]\ttraining's binary_logloss: 0.486175\tvalid_1's binary_logloss: 0.487319\n",
      "[150]\ttraining's binary_logloss: 0.476127\tvalid_1's binary_logloss: 0.477974\n",
      "[200]\ttraining's binary_logloss: 0.469386\tvalid_1's binary_logloss: 0.471972\n",
      "[250]\ttraining's binary_logloss: 0.464221\tvalid_1's binary_logloss: 0.46749\n",
      "[300]\ttraining's binary_logloss: 0.460048\tvalid_1's binary_logloss: 0.46403\n",
      "[350]\ttraining's binary_logloss: 0.45632\tvalid_1's binary_logloss: 0.461014\n",
      "[400]\ttraining's binary_logloss: 0.453007\tvalid_1's binary_logloss: 0.458348\n",
      "[450]\ttraining's binary_logloss: 0.450068\tvalid_1's binary_logloss: 0.456064\n",
      "[500]\ttraining's binary_logloss: 0.447496\tvalid_1's binary_logloss: 0.454165\n",
      "[550]\ttraining's binary_logloss: 0.445038\tvalid_1's binary_logloss: 0.452351\n",
      "[600]\ttraining's binary_logloss: 0.442899\tvalid_1's binary_logloss: 0.450868\n",
      "[650]\ttraining's binary_logloss: 0.440878\tvalid_1's binary_logloss: 0.449549\n",
      "[700]\ttraining's binary_logloss: 0.438975\tvalid_1's binary_logloss: 0.448321\n",
      "[750]\ttraining's binary_logloss: 0.437091\tvalid_1's binary_logloss: 0.447109\n",
      "[800]\ttraining's binary_logloss: 0.435417\tvalid_1's binary_logloss: 0.446112\n",
      "[850]\ttraining's binary_logloss: 0.433872\tvalid_1's binary_logloss: 0.445208\n",
      "[900]\ttraining's binary_logloss: 0.432249\tvalid_1's binary_logloss: 0.444231\n",
      "[950]\ttraining's binary_logloss: 0.430765\tvalid_1's binary_logloss: 0.443412\n",
      "[1000]\ttraining's binary_logloss: 0.429223\tvalid_1's binary_logloss: 0.442482\n",
      "[1050]\ttraining's binary_logloss: 0.427754\tvalid_1's binary_logloss: 0.441648\n",
      "[1100]\ttraining's binary_logloss: 0.426265\tvalid_1's binary_logloss: 0.440852\n",
      "[1150]\ttraining's binary_logloss: 0.424831\tvalid_1's binary_logloss: 0.440034\n",
      "[1200]\ttraining's binary_logloss: 0.423638\tvalid_1's binary_logloss: 0.439434\n",
      "[1250]\ttraining's binary_logloss: 0.422402\tvalid_1's binary_logloss: 0.438866\n",
      "[1300]\ttraining's binary_logloss: 0.421209\tvalid_1's binary_logloss: 0.438267\n",
      "[1350]\ttraining's binary_logloss: 0.420191\tvalid_1's binary_logloss: 0.437873\n",
      "[1400]\ttraining's binary_logloss: 0.419084\tvalid_1's binary_logloss: 0.437393\n",
      "[1450]\ttraining's binary_logloss: 0.417991\tvalid_1's binary_logloss: 0.436918\n",
      "[1500]\ttraining's binary_logloss: 0.416987\tvalid_1's binary_logloss: 0.436486\n",
      "[1550]\ttraining's binary_logloss: 0.415982\tvalid_1's binary_logloss: 0.436077\n",
      "[1600]\ttraining's binary_logloss: 0.415006\tvalid_1's binary_logloss: 0.435645\n",
      "[1650]\ttraining's binary_logloss: 0.413969\tvalid_1's binary_logloss: 0.435205\n",
      "[1700]\ttraining's binary_logloss: 0.412979\tvalid_1's binary_logloss: 0.434756\n",
      "[1750]\ttraining's binary_logloss: 0.412013\tvalid_1's binary_logloss: 0.434368\n",
      "[1800]\ttraining's binary_logloss: 0.411049\tvalid_1's binary_logloss: 0.433996\n",
      "[1850]\ttraining's binary_logloss: 0.410173\tvalid_1's binary_logloss: 0.433668\n",
      "[1900]\ttraining's binary_logloss: 0.409344\tvalid_1's binary_logloss: 0.433425\n",
      "[1950]\ttraining's binary_logloss: 0.408441\tvalid_1's binary_logloss: 0.433071\n",
      "[2000]\ttraining's binary_logloss: 0.407626\tvalid_1's binary_logloss: 0.432795\n",
      "[2050]\ttraining's binary_logloss: 0.406819\tvalid_1's binary_logloss: 0.432534\n",
      "[2100]\ttraining's binary_logloss: 0.406018\tvalid_1's binary_logloss: 0.43226\n",
      "[2150]\ttraining's binary_logloss: 0.40522\tvalid_1's binary_logloss: 0.431974\n",
      "[2200]\ttraining's binary_logloss: 0.40444\tvalid_1's binary_logloss: 0.431718\n",
      "[2250]\ttraining's binary_logloss: 0.403696\tvalid_1's binary_logloss: 0.431497\n",
      "[2300]\ttraining's binary_logloss: 0.402914\tvalid_1's binary_logloss: 0.431273\n",
      "[2350]\ttraining's binary_logloss: 0.402131\tvalid_1's binary_logloss: 0.431039\n",
      "[2400]\ttraining's binary_logloss: 0.40133\tvalid_1's binary_logloss: 0.430766\n",
      "[2450]\ttraining's binary_logloss: 0.400567\tvalid_1's binary_logloss: 0.430552\n",
      "[2500]\ttraining's binary_logloss: 0.399763\tvalid_1's binary_logloss: 0.43029\n",
      "[2550]\ttraining's binary_logloss: 0.399081\tvalid_1's binary_logloss: 0.430117\n",
      "[2600]\ttraining's binary_logloss: 0.398337\tvalid_1's binary_logloss: 0.429886\n",
      "[2650]\ttraining's binary_logloss: 0.39762\tvalid_1's binary_logloss: 0.429685\n",
      "[2700]\ttraining's binary_logloss: 0.396828\tvalid_1's binary_logloss: 0.429469\n",
      "[2750]\ttraining's binary_logloss: 0.396071\tvalid_1's binary_logloss: 0.429253\n",
      "[2800]\ttraining's binary_logloss: 0.395373\tvalid_1's binary_logloss: 0.429051\n",
      "[2850]\ttraining's binary_logloss: 0.394681\tvalid_1's binary_logloss: 0.428839\n",
      "[2900]\ttraining's binary_logloss: 0.393971\tvalid_1's binary_logloss: 0.428617\n",
      "[2950]\ttraining's binary_logloss: 0.393249\tvalid_1's binary_logloss: 0.428416\n",
      "[3000]\ttraining's binary_logloss: 0.392575\tvalid_1's binary_logloss: 0.428216\n",
      "[3050]\ttraining's binary_logloss: 0.391891\tvalid_1's binary_logloss: 0.42801\n",
      "[3100]\ttraining's binary_logloss: 0.39126\tvalid_1's binary_logloss: 0.427842\n",
      "[3150]\ttraining's binary_logloss: 0.390644\tvalid_1's binary_logloss: 0.427707\n",
      "[3200]\ttraining's binary_logloss: 0.390097\tvalid_1's binary_logloss: 0.427586\n",
      "[3250]\ttraining's binary_logloss: 0.389522\tvalid_1's binary_logloss: 0.427413\n",
      "[3300]\ttraining's binary_logloss: 0.388946\tvalid_1's binary_logloss: 0.427304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3350]\ttraining's binary_logloss: 0.388323\tvalid_1's binary_logloss: 0.427141\n",
      "[3400]\ttraining's binary_logloss: 0.387703\tvalid_1's binary_logloss: 0.426967\n",
      "[3450]\ttraining's binary_logloss: 0.387104\tvalid_1's binary_logloss: 0.426818\n",
      "[3500]\ttraining's binary_logloss: 0.386537\tvalid_1's binary_logloss: 0.426702\n",
      "[3550]\ttraining's binary_logloss: 0.386007\tvalid_1's binary_logloss: 0.426597\n",
      "[3600]\ttraining's binary_logloss: 0.385503\tvalid_1's binary_logloss: 0.426535\n",
      "[3650]\ttraining's binary_logloss: 0.384946\tvalid_1's binary_logloss: 0.426459\n",
      "[3700]\ttraining's binary_logloss: 0.384372\tvalid_1's binary_logloss: 0.426322\n",
      "[3750]\ttraining's binary_logloss: 0.383767\tvalid_1's binary_logloss: 0.426191\n",
      "[3800]\ttraining's binary_logloss: 0.383218\tvalid_1's binary_logloss: 0.426076\n",
      "[3850]\ttraining's binary_logloss: 0.382616\tvalid_1's binary_logloss: 0.425931\n",
      "[3900]\ttraining's binary_logloss: 0.382056\tvalid_1's binary_logloss: 0.425802\n",
      "[3950]\ttraining's binary_logloss: 0.381541\tvalid_1's binary_logloss: 0.425713\n",
      "[4000]\ttraining's binary_logloss: 0.381025\tvalid_1's binary_logloss: 0.42562\n",
      "[4050]\ttraining's binary_logloss: 0.380521\tvalid_1's binary_logloss: 0.425538\n",
      "[4100]\ttraining's binary_logloss: 0.37999\tvalid_1's binary_logloss: 0.42541\n",
      "[4150]\ttraining's binary_logloss: 0.379481\tvalid_1's binary_logloss: 0.425329\n",
      "[4200]\ttraining's binary_logloss: 0.378986\tvalid_1's binary_logloss: 0.425256\n",
      "[4250]\ttraining's binary_logloss: 0.378492\tvalid_1's binary_logloss: 0.425209\n",
      "[4300]\ttraining's binary_logloss: 0.378003\tvalid_1's binary_logloss: 0.425123\n",
      "[4350]\ttraining's binary_logloss: 0.377524\tvalid_1's binary_logloss: 0.425041\n",
      "[4400]\ttraining's binary_logloss: 0.377021\tvalid_1's binary_logloss: 0.424939\n",
      "[4450]\ttraining's binary_logloss: 0.376564\tvalid_1's binary_logloss: 0.424867\n",
      "[4500]\ttraining's binary_logloss: 0.37609\tvalid_1's binary_logloss: 0.424762\n",
      "[4550]\ttraining's binary_logloss: 0.375617\tvalid_1's binary_logloss: 0.424699\n",
      "[4600]\ttraining's binary_logloss: 0.375156\tvalid_1's binary_logloss: 0.424619\n",
      "[4650]\ttraining's binary_logloss: 0.374704\tvalid_1's binary_logloss: 0.424537\n",
      "[4700]\ttraining's binary_logloss: 0.374258\tvalid_1's binary_logloss: 0.424482\n",
      "[4750]\ttraining's binary_logloss: 0.373823\tvalid_1's binary_logloss: 0.424422\n",
      "[4800]\ttraining's binary_logloss: 0.373437\tvalid_1's binary_logloss: 0.42439\n",
      "[4850]\ttraining's binary_logloss: 0.373012\tvalid_1's binary_logloss: 0.424329\n",
      "[4900]\ttraining's binary_logloss: 0.372595\tvalid_1's binary_logloss: 0.424278\n",
      "[4950]\ttraining's binary_logloss: 0.372154\tvalid_1's binary_logloss: 0.424225\n",
      "[5000]\ttraining's binary_logloss: 0.371723\tvalid_1's binary_logloss: 0.424157\n",
      "[5050]\ttraining's binary_logloss: 0.371255\tvalid_1's binary_logloss: 0.424095\n",
      "[5100]\ttraining's binary_logloss: 0.370809\tvalid_1's binary_logloss: 0.424054\n",
      "[5150]\ttraining's binary_logloss: 0.370392\tvalid_1's binary_logloss: 0.424014\n",
      "[5200]\ttraining's binary_logloss: 0.369993\tvalid_1's binary_logloss: 0.423958\n",
      "[5250]\ttraining's binary_logloss: 0.369593\tvalid_1's binary_logloss: 0.423932\n",
      "[5300]\ttraining's binary_logloss: 0.369181\tvalid_1's binary_logloss: 0.423891\n",
      "[5350]\ttraining's binary_logloss: 0.368759\tvalid_1's binary_logloss: 0.423837\n",
      "[5400]\ttraining's binary_logloss: 0.368383\tvalid_1's binary_logloss: 0.423805\n",
      "[5450]\ttraining's binary_logloss: 0.368011\tvalid_1's binary_logloss: 0.423793\n",
      "[5500]\ttraining's binary_logloss: 0.36762\tvalid_1's binary_logloss: 0.423759\n",
      "[5550]\ttraining's binary_logloss: 0.367196\tvalid_1's binary_logloss: 0.423719\n",
      "[5600]\ttraining's binary_logloss: 0.366815\tvalid_1's binary_logloss: 0.423694\n",
      "[5650]\ttraining's binary_logloss: 0.366433\tvalid_1's binary_logloss: 0.423668\n",
      "[5700]\ttraining's binary_logloss: 0.366069\tvalid_1's binary_logloss: 0.423632\n",
      "[5750]\ttraining's binary_logloss: 0.365646\tvalid_1's binary_logloss: 0.423588\n",
      "[5800]\ttraining's binary_logloss: 0.365251\tvalid_1's binary_logloss: 0.423547\n",
      "[5850]\ttraining's binary_logloss: 0.364923\tvalid_1's binary_logloss: 0.423539\n",
      "[5900]\ttraining's binary_logloss: 0.364522\tvalid_1's binary_logloss: 0.423505\n",
      "[5950]\ttraining's binary_logloss: 0.364149\tvalid_1's binary_logloss: 0.423474\n",
      "[6000]\ttraining's binary_logloss: 0.363777\tvalid_1's binary_logloss: 0.423469\n",
      "[6050]\ttraining's binary_logloss: 0.363437\tvalid_1's binary_logloss: 0.423447\n",
      "[6100]\ttraining's binary_logloss: 0.363094\tvalid_1's binary_logloss: 0.423413\n",
      "[6150]\ttraining's binary_logloss: 0.362725\tvalid_1's binary_logloss: 0.423386\n",
      "[6200]\ttraining's binary_logloss: 0.362368\tvalid_1's binary_logloss: 0.423381\n",
      "[6250]\ttraining's binary_logloss: 0.362036\tvalid_1's binary_logloss: 0.423363\n",
      "[6300]\ttraining's binary_logloss: 0.361721\tvalid_1's binary_logloss: 0.423342\n",
      "[6350]\ttraining's binary_logloss: 0.361363\tvalid_1's binary_logloss: 0.423318\n",
      "[6400]\ttraining's binary_logloss: 0.360998\tvalid_1's binary_logloss: 0.4233\n",
      "[6450]\ttraining's binary_logloss: 0.360702\tvalid_1's binary_logloss: 0.423306\n",
      "[6500]\ttraining's binary_logloss: 0.360346\tvalid_1's binary_logloss: 0.423282\n",
      "[6550]\ttraining's binary_logloss: 0.360016\tvalid_1's binary_logloss: 0.423264\n",
      "[6600]\ttraining's binary_logloss: 0.359689\tvalid_1's binary_logloss: 0.423268\n",
      "[6650]\ttraining's binary_logloss: 0.359352\tvalid_1's binary_logloss: 0.423247\n",
      "[6700]\ttraining's binary_logloss: 0.359037\tvalid_1's binary_logloss: 0.423243\n",
      "[6750]\ttraining's binary_logloss: 0.35868\tvalid_1's binary_logloss: 0.423229\n",
      "[6800]\ttraining's binary_logloss: 0.358333\tvalid_1's binary_logloss: 0.423215\n",
      "[6850]\ttraining's binary_logloss: 0.357986\tvalid_1's binary_logloss: 0.423195\n",
      "[6900]\ttraining's binary_logloss: 0.357662\tvalid_1's binary_logloss: 0.42319\n",
      "[6950]\ttraining's binary_logloss: 0.357411\tvalid_1's binary_logloss: 0.4232\n",
      "[7000]\ttraining's binary_logloss: 0.357103\tvalid_1's binary_logloss: 0.423195\n",
      "[7050]\ttraining's binary_logloss: 0.356769\tvalid_1's binary_logloss: 0.423182\n",
      "[7100]\ttraining's binary_logloss: 0.356483\tvalid_1's binary_logloss: 0.423194\n",
      "[7150]\ttraining's binary_logloss: 0.356208\tvalid_1's binary_logloss: 0.423214\n",
      "[7200]\ttraining's binary_logloss: 0.355917\tvalid_1's binary_logloss: 0.423226\n",
      "Early stopping, best iteration is:\n",
      "[7055]\ttraining's binary_logloss: 0.35674\tvalid_1's binary_logloss: 0.423177\n",
      "最大f1为 0.8072594014483903\n",
      "此时阈值为: 0.42900000000000016\n",
      "kflod: 2\n",
      "Training until validation scores don't improve for 150 rounds.\n",
      "[50]\ttraining's binary_logloss: 0.504505\tvalid_1's binary_logloss: 0.505571\n",
      "[100]\ttraining's binary_logloss: 0.485963\tvalid_1's binary_logloss: 0.487794\n",
      "[150]\ttraining's binary_logloss: 0.476203\tvalid_1's binary_logloss: 0.47871\n",
      "[200]\ttraining's binary_logloss: 0.46961\tvalid_1's binary_logloss: 0.472782\n",
      "[250]\ttraining's binary_logloss: 0.464865\tvalid_1's binary_logloss: 0.468729\n",
      "[300]\ttraining's binary_logloss: 0.460174\tvalid_1's binary_logloss: 0.46471\n",
      "[350]\ttraining's binary_logloss: 0.456356\tvalid_1's binary_logloss: 0.461552\n",
      "[400]\ttraining's binary_logloss: 0.453207\tvalid_1's binary_logloss: 0.459094\n",
      "[450]\ttraining's binary_logloss: 0.450322\tvalid_1's binary_logloss: 0.456899\n",
      "[500]\ttraining's binary_logloss: 0.44776\tvalid_1's binary_logloss: 0.455045\n",
      "[550]\ttraining's binary_logloss: 0.445514\tvalid_1's binary_logloss: 0.453432\n",
      "[600]\ttraining's binary_logloss: 0.443188\tvalid_1's binary_logloss: 0.4518\n",
      "[650]\ttraining's binary_logloss: 0.441074\tvalid_1's binary_logloss: 0.450346\n",
      "[700]\ttraining's binary_logloss: 0.439254\tvalid_1's binary_logloss: 0.449189\n",
      "[750]\ttraining's binary_logloss: 0.437474\tvalid_1's binary_logloss: 0.448041\n",
      "[800]\ttraining's binary_logloss: 0.435731\tvalid_1's binary_logloss: 0.44696\n",
      "[850]\ttraining's binary_logloss: 0.434124\tvalid_1's binary_logloss: 0.445976\n",
      "[900]\ttraining's binary_logloss: 0.432637\tvalid_1's binary_logloss: 0.445157\n",
      "[950]\ttraining's binary_logloss: 0.431283\tvalid_1's binary_logloss: 0.444453\n",
      "[1000]\ttraining's binary_logloss: 0.429703\tvalid_1's binary_logloss: 0.443497\n",
      "[1050]\ttraining's binary_logloss: 0.4282\tvalid_1's binary_logloss: 0.44266\n",
      "[1100]\ttraining's binary_logloss: 0.426809\tvalid_1's binary_logloss: 0.441851\n",
      "[1150]\ttraining's binary_logloss: 0.425457\tvalid_1's binary_logloss: 0.441139\n",
      "[1200]\ttraining's binary_logloss: 0.424206\tvalid_1's binary_logloss: 0.440433\n",
      "[1250]\ttraining's binary_logloss: 0.423007\tvalid_1's binary_logloss: 0.439833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1300]\ttraining's binary_logloss: 0.421799\tvalid_1's binary_logloss: 0.439246\n",
      "[1350]\ttraining's binary_logloss: 0.420647\tvalid_1's binary_logloss: 0.43873\n",
      "[1400]\ttraining's binary_logloss: 0.419534\tvalid_1's binary_logloss: 0.438206\n",
      "[1450]\ttraining's binary_logloss: 0.418432\tvalid_1's binary_logloss: 0.437743\n",
      "[1500]\ttraining's binary_logloss: 0.4173\tvalid_1's binary_logloss: 0.437255\n",
      "[1550]\ttraining's binary_logloss: 0.41621\tvalid_1's binary_logloss: 0.436753\n",
      "[1600]\ttraining's binary_logloss: 0.415181\tvalid_1's binary_logloss: 0.436336\n",
      "[1650]\ttraining's binary_logloss: 0.414219\tvalid_1's binary_logloss: 0.435936\n",
      "[1700]\ttraining's binary_logloss: 0.413284\tvalid_1's binary_logloss: 0.435585\n",
      "[1750]\ttraining's binary_logloss: 0.412381\tvalid_1's binary_logloss: 0.435217\n",
      "[1800]\ttraining's binary_logloss: 0.411502\tvalid_1's binary_logloss: 0.434866\n",
      "[1850]\ttraining's binary_logloss: 0.410567\tvalid_1's binary_logloss: 0.434507\n",
      "[1900]\ttraining's binary_logloss: 0.409614\tvalid_1's binary_logloss: 0.434148\n",
      "[1950]\ttraining's binary_logloss: 0.408711\tvalid_1's binary_logloss: 0.43383\n",
      "[2000]\ttraining's binary_logloss: 0.40782\tvalid_1's binary_logloss: 0.433501\n",
      "[2050]\ttraining's binary_logloss: 0.407036\tvalid_1's binary_logloss: 0.43329\n",
      "[2100]\ttraining's binary_logloss: 0.406187\tvalid_1's binary_logloss: 0.432969\n",
      "[2150]\ttraining's binary_logloss: 0.405355\tvalid_1's binary_logloss: 0.432665\n",
      "[2200]\ttraining's binary_logloss: 0.404572\tvalid_1's binary_logloss: 0.432424\n",
      "[2250]\ttraining's binary_logloss: 0.403752\tvalid_1's binary_logloss: 0.432161\n",
      "[2300]\ttraining's binary_logloss: 0.40301\tvalid_1's binary_logloss: 0.431897\n",
      "[2350]\ttraining's binary_logloss: 0.402225\tvalid_1's binary_logloss: 0.431608\n",
      "[2400]\ttraining's binary_logloss: 0.401487\tvalid_1's binary_logloss: 0.431397\n",
      "[2450]\ttraining's binary_logloss: 0.400786\tvalid_1's binary_logloss: 0.431173\n",
      "[2500]\ttraining's binary_logloss: 0.399979\tvalid_1's binary_logloss: 0.430878\n",
      "[2550]\ttraining's binary_logloss: 0.399201\tvalid_1's binary_logloss: 0.430613\n",
      "[2600]\ttraining's binary_logloss: 0.398456\tvalid_1's binary_logloss: 0.430398\n",
      "[2650]\ttraining's binary_logloss: 0.397813\tvalid_1's binary_logloss: 0.430216\n",
      "[2700]\ttraining's binary_logloss: 0.397138\tvalid_1's binary_logloss: 0.43002\n",
      "[2750]\ttraining's binary_logloss: 0.396502\tvalid_1's binary_logloss: 0.42985\n",
      "[2800]\ttraining's binary_logloss: 0.395806\tvalid_1's binary_logloss: 0.429681\n",
      "[2850]\ttraining's binary_logloss: 0.395115\tvalid_1's binary_logloss: 0.429485\n",
      "[2900]\ttraining's binary_logloss: 0.394472\tvalid_1's binary_logloss: 0.429309\n",
      "[2950]\ttraining's binary_logloss: 0.393797\tvalid_1's binary_logloss: 0.42914\n",
      "[3000]\ttraining's binary_logloss: 0.393157\tvalid_1's binary_logloss: 0.428983\n",
      "[3050]\ttraining's binary_logloss: 0.392534\tvalid_1's binary_logloss: 0.428824\n",
      "[3100]\ttraining's binary_logloss: 0.391906\tvalid_1's binary_logloss: 0.428647\n",
      "[3150]\ttraining's binary_logloss: 0.391295\tvalid_1's binary_logloss: 0.428505\n",
      "[3200]\ttraining's binary_logloss: 0.390658\tvalid_1's binary_logloss: 0.428323\n",
      "[3250]\ttraining's binary_logloss: 0.390027\tvalid_1's binary_logloss: 0.428162\n",
      "[3300]\ttraining's binary_logloss: 0.389419\tvalid_1's binary_logloss: 0.428031\n",
      "[3350]\ttraining's binary_logloss: 0.388833\tvalid_1's binary_logloss: 0.427878\n",
      "[3400]\ttraining's binary_logloss: 0.388298\tvalid_1's binary_logloss: 0.427786\n",
      "[3450]\ttraining's binary_logloss: 0.387709\tvalid_1's binary_logloss: 0.427663\n",
      "[3500]\ttraining's binary_logloss: 0.387138\tvalid_1's binary_logloss: 0.427508\n",
      "[3550]\ttraining's binary_logloss: 0.386507\tvalid_1's binary_logloss: 0.427311\n",
      "[3600]\ttraining's binary_logloss: 0.385961\tvalid_1's binary_logloss: 0.427196\n",
      "[3650]\ttraining's binary_logloss: 0.385399\tvalid_1's binary_logloss: 0.427052\n",
      "[3700]\ttraining's binary_logloss: 0.384853\tvalid_1's binary_logloss: 0.426926\n",
      "[3750]\ttraining's binary_logloss: 0.384304\tvalid_1's binary_logloss: 0.426824\n",
      "[3800]\ttraining's binary_logloss: 0.383741\tvalid_1's binary_logloss: 0.426679\n",
      "[3850]\ttraining's binary_logloss: 0.383236\tvalid_1's binary_logloss: 0.426545\n",
      "[3900]\ttraining's binary_logloss: 0.382701\tvalid_1's binary_logloss: 0.426444\n",
      "[3950]\ttraining's binary_logloss: 0.382137\tvalid_1's binary_logloss: 0.426305\n",
      "[4000]\ttraining's binary_logloss: 0.3816\tvalid_1's binary_logloss: 0.426182\n",
      "[4050]\ttraining's binary_logloss: 0.381094\tvalid_1's binary_logloss: 0.426086\n",
      "[4100]\ttraining's binary_logloss: 0.380557\tvalid_1's binary_logloss: 0.42597\n",
      "[4150]\ttraining's binary_logloss: 0.38002\tvalid_1's binary_logloss: 0.42583\n",
      "[4200]\ttraining's binary_logloss: 0.379518\tvalid_1's binary_logloss: 0.425733\n",
      "[4250]\ttraining's binary_logloss: 0.37902\tvalid_1's binary_logloss: 0.425634\n",
      "[4300]\ttraining's binary_logloss: 0.378484\tvalid_1's binary_logloss: 0.425515\n",
      "[4350]\ttraining's binary_logloss: 0.377962\tvalid_1's binary_logloss: 0.425439\n",
      "[4400]\ttraining's binary_logloss: 0.377456\tvalid_1's binary_logloss: 0.425369\n",
      "[4450]\ttraining's binary_logloss: 0.376963\tvalid_1's binary_logloss: 0.425302\n",
      "[4500]\ttraining's binary_logloss: 0.376506\tvalid_1's binary_logloss: 0.425255\n",
      "[4550]\ttraining's binary_logloss: 0.376104\tvalid_1's binary_logloss: 0.425223\n",
      "[4600]\ttraining's binary_logloss: 0.375612\tvalid_1's binary_logloss: 0.425142\n",
      "[4650]\ttraining's binary_logloss: 0.375144\tvalid_1's binary_logloss: 0.425087\n",
      "[4700]\ttraining's binary_logloss: 0.374732\tvalid_1's binary_logloss: 0.425046\n",
      "[4750]\ttraining's binary_logloss: 0.374288\tvalid_1's binary_logloss: 0.424993\n",
      "[4800]\ttraining's binary_logloss: 0.37387\tvalid_1's binary_logloss: 0.424959\n",
      "[4850]\ttraining's binary_logloss: 0.373401\tvalid_1's binary_logloss: 0.42489\n",
      "[4900]\ttraining's binary_logloss: 0.372941\tvalid_1's binary_logloss: 0.424826\n",
      "[4950]\ttraining's binary_logloss: 0.372535\tvalid_1's binary_logloss: 0.424769\n",
      "[5000]\ttraining's binary_logloss: 0.372137\tvalid_1's binary_logloss: 0.424747\n",
      "[5050]\ttraining's binary_logloss: 0.371751\tvalid_1's binary_logloss: 0.424706\n",
      "[5100]\ttraining's binary_logloss: 0.371372\tvalid_1's binary_logloss: 0.424669\n",
      "[5150]\ttraining's binary_logloss: 0.370932\tvalid_1's binary_logloss: 0.424615\n",
      "[5200]\ttraining's binary_logloss: 0.370478\tvalid_1's binary_logloss: 0.424529\n",
      "[5250]\ttraining's binary_logloss: 0.370081\tvalid_1's binary_logloss: 0.424488\n",
      "[5300]\ttraining's binary_logloss: 0.369642\tvalid_1's binary_logloss: 0.424436\n",
      "[5350]\ttraining's binary_logloss: 0.36923\tvalid_1's binary_logloss: 0.424407\n",
      "[5400]\ttraining's binary_logloss: 0.368777\tvalid_1's binary_logloss: 0.424357\n",
      "[5450]\ttraining's binary_logloss: 0.368381\tvalid_1's binary_logloss: 0.42431\n",
      "[5500]\ttraining's binary_logloss: 0.367955\tvalid_1's binary_logloss: 0.424258\n",
      "[5550]\ttraining's binary_logloss: 0.367563\tvalid_1's binary_logloss: 0.424215\n",
      "[5600]\ttraining's binary_logloss: 0.367165\tvalid_1's binary_logloss: 0.424177\n",
      "[5650]\ttraining's binary_logloss: 0.366817\tvalid_1's binary_logloss: 0.424158\n",
      "[5700]\ttraining's binary_logloss: 0.366426\tvalid_1's binary_logloss: 0.424123\n",
      "[5750]\ttraining's binary_logloss: 0.366015\tvalid_1's binary_logloss: 0.424073\n",
      "[5800]\ttraining's binary_logloss: 0.365618\tvalid_1's binary_logloss: 0.42404\n",
      "[5850]\ttraining's binary_logloss: 0.365211\tvalid_1's binary_logloss: 0.42399\n",
      "[5900]\ttraining's binary_logloss: 0.364874\tvalid_1's binary_logloss: 0.423976\n",
      "[5950]\ttraining's binary_logloss: 0.36449\tvalid_1's binary_logloss: 0.423947\n",
      "[6000]\ttraining's binary_logloss: 0.364154\tvalid_1's binary_logloss: 0.423931\n",
      "[6050]\ttraining's binary_logloss: 0.363818\tvalid_1's binary_logloss: 0.423907\n",
      "[6100]\ttraining's binary_logloss: 0.363455\tvalid_1's binary_logloss: 0.423883\n",
      "[6150]\ttraining's binary_logloss: 0.363104\tvalid_1's binary_logloss: 0.423871\n",
      "[6200]\ttraining's binary_logloss: 0.362744\tvalid_1's binary_logloss: 0.423849\n",
      "[6250]\ttraining's binary_logloss: 0.362381\tvalid_1's binary_logloss: 0.423827\n",
      "[6300]\ttraining's binary_logloss: 0.362043\tvalid_1's binary_logloss: 0.423811\n",
      "[6350]\ttraining's binary_logloss: 0.361719\tvalid_1's binary_logloss: 0.423802\n",
      "[6400]\ttraining's binary_logloss: 0.361395\tvalid_1's binary_logloss: 0.423803\n",
      "[6450]\ttraining's binary_logloss: 0.361021\tvalid_1's binary_logloss: 0.42378\n",
      "[6500]\ttraining's binary_logloss: 0.360671\tvalid_1's binary_logloss: 0.423756\n",
      "[6550]\ttraining's binary_logloss: 0.360357\tvalid_1's binary_logloss: 0.423754\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6600]\ttraining's binary_logloss: 0.360039\tvalid_1's binary_logloss: 0.423757\n",
      "[6650]\ttraining's binary_logloss: 0.359714\tvalid_1's binary_logloss: 0.42374\n",
      "[6700]\ttraining's binary_logloss: 0.359399\tvalid_1's binary_logloss: 0.423725\n",
      "[6750]\ttraining's binary_logloss: 0.359088\tvalid_1's binary_logloss: 0.423716\n",
      "[6800]\ttraining's binary_logloss: 0.358768\tvalid_1's binary_logloss: 0.423703\n",
      "[6850]\ttraining's binary_logloss: 0.358442\tvalid_1's binary_logloss: 0.423685\n",
      "[6900]\ttraining's binary_logloss: 0.358108\tvalid_1's binary_logloss: 0.423675\n",
      "[6950]\ttraining's binary_logloss: 0.357806\tvalid_1's binary_logloss: 0.423671\n",
      "[7000]\ttraining's binary_logloss: 0.357499\tvalid_1's binary_logloss: 0.423659\n",
      "[7050]\ttraining's binary_logloss: 0.357199\tvalid_1's binary_logloss: 0.423672\n",
      "[7100]\ttraining's binary_logloss: 0.356889\tvalid_1's binary_logloss: 0.423661\n",
      "[7150]\ttraining's binary_logloss: 0.35658\tvalid_1's binary_logloss: 0.423663\n",
      "[7200]\ttraining's binary_logloss: 0.356301\tvalid_1's binary_logloss: 0.423686\n",
      "[7250]\ttraining's binary_logloss: 0.356\tvalid_1's binary_logloss: 0.42368\n",
      "Early stopping, best iteration is:\n",
      "[7134]\ttraining's binary_logloss: 0.356675\tvalid_1's binary_logloss: 0.423651\n",
      "最大f1为 0.806332791477882\n",
      "此时阈值为: 0.41800000000000015\n",
      "kflod: 3\n",
      "Training until validation scores don't improve for 150 rounds.\n",
      "[50]\ttraining's binary_logloss: 0.504499\tvalid_1's binary_logloss: 0.505454\n",
      "[100]\ttraining's binary_logloss: 0.486016\tvalid_1's binary_logloss: 0.487759\n",
      "[150]\ttraining's binary_logloss: 0.476215\tvalid_1's binary_logloss: 0.478646\n",
      "[200]\ttraining's binary_logloss: 0.46951\tvalid_1's binary_logloss: 0.472603\n",
      "[250]\ttraining's binary_logloss: 0.463982\tvalid_1's binary_logloss: 0.467771\n",
      "[300]\ttraining's binary_logloss: 0.459756\tvalid_1's binary_logloss: 0.464252\n",
      "[350]\ttraining's binary_logloss: 0.45628\tvalid_1's binary_logloss: 0.461484\n",
      "[400]\ttraining's binary_logloss: 0.453007\tvalid_1's binary_logloss: 0.458868\n",
      "[450]\ttraining's binary_logloss: 0.450116\tvalid_1's binary_logloss: 0.456678\n",
      "[500]\ttraining's binary_logloss: 0.447654\tvalid_1's binary_logloss: 0.454855\n",
      "[550]\ttraining's binary_logloss: 0.445144\tvalid_1's binary_logloss: 0.453014\n",
      "[600]\ttraining's binary_logloss: 0.443007\tvalid_1's binary_logloss: 0.451515\n",
      "[650]\ttraining's binary_logloss: 0.440946\tvalid_1's binary_logloss: 0.450116\n",
      "[700]\ttraining's binary_logloss: 0.439116\tvalid_1's binary_logloss: 0.44899\n",
      "[750]\ttraining's binary_logloss: 0.437273\tvalid_1's binary_logloss: 0.447798\n",
      "[800]\ttraining's binary_logloss: 0.435551\tvalid_1's binary_logloss: 0.446749\n",
      "[850]\ttraining's binary_logloss: 0.433994\tvalid_1's binary_logloss: 0.445874\n",
      "[900]\ttraining's binary_logloss: 0.432413\tvalid_1's binary_logloss: 0.444903\n",
      "[950]\ttraining's binary_logloss: 0.430823\tvalid_1's binary_logloss: 0.443946\n",
      "[1000]\ttraining's binary_logloss: 0.429291\tvalid_1's binary_logloss: 0.443054\n",
      "[1050]\ttraining's binary_logloss: 0.428022\tvalid_1's binary_logloss: 0.442429\n",
      "[1100]\ttraining's binary_logloss: 0.426619\tvalid_1's binary_logloss: 0.441619\n",
      "[1150]\ttraining's binary_logloss: 0.425357\tvalid_1's binary_logloss: 0.440971\n",
      "[1200]\ttraining's binary_logloss: 0.424137\tvalid_1's binary_logloss: 0.440363\n",
      "[1250]\ttraining's binary_logloss: 0.422783\tvalid_1's binary_logloss: 0.43969\n",
      "[1300]\ttraining's binary_logloss: 0.421573\tvalid_1's binary_logloss: 0.439121\n",
      "[1350]\ttraining's binary_logloss: 0.420383\tvalid_1's binary_logloss: 0.438536\n",
      "[1400]\ttraining's binary_logloss: 0.419274\tvalid_1's binary_logloss: 0.438\n",
      "[1450]\ttraining's binary_logloss: 0.418114\tvalid_1's binary_logloss: 0.437429\n",
      "[1500]\ttraining's binary_logloss: 0.417021\tvalid_1's binary_logloss: 0.436934\n",
      "[1550]\ttraining's binary_logloss: 0.416019\tvalid_1's binary_logloss: 0.436483\n",
      "[1600]\ttraining's binary_logloss: 0.414999\tvalid_1's binary_logloss: 0.436013\n",
      "[1650]\ttraining's binary_logloss: 0.413953\tvalid_1's binary_logloss: 0.435555\n",
      "[1700]\ttraining's binary_logloss: 0.413041\tvalid_1's binary_logloss: 0.435215\n",
      "[1750]\ttraining's binary_logloss: 0.412109\tvalid_1's binary_logloss: 0.434855\n",
      "[1800]\ttraining's binary_logloss: 0.411128\tvalid_1's binary_logloss: 0.434424\n",
      "[1850]\ttraining's binary_logloss: 0.410217\tvalid_1's binary_logloss: 0.434082\n",
      "[1900]\ttraining's binary_logloss: 0.40934\tvalid_1's binary_logloss: 0.433785\n",
      "[1950]\ttraining's binary_logloss: 0.408469\tvalid_1's binary_logloss: 0.433503\n",
      "[2000]\ttraining's binary_logloss: 0.407648\tvalid_1's binary_logloss: 0.433235\n",
      "[2050]\ttraining's binary_logloss: 0.406787\tvalid_1's binary_logloss: 0.432921\n",
      "[2100]\ttraining's binary_logloss: 0.405872\tvalid_1's binary_logloss: 0.43256\n",
      "[2150]\ttraining's binary_logloss: 0.405005\tvalid_1's binary_logloss: 0.432209\n",
      "[2200]\ttraining's binary_logloss: 0.404203\tvalid_1's binary_logloss: 0.431967\n",
      "[2250]\ttraining's binary_logloss: 0.403425\tvalid_1's binary_logloss: 0.431763\n",
      "[2300]\ttraining's binary_logloss: 0.402566\tvalid_1's binary_logloss: 0.431452\n",
      "[2350]\ttraining's binary_logloss: 0.401774\tvalid_1's binary_logloss: 0.431251\n",
      "[2400]\ttraining's binary_logloss: 0.401008\tvalid_1's binary_logloss: 0.430996\n",
      "[2450]\ttraining's binary_logloss: 0.400285\tvalid_1's binary_logloss: 0.430814\n",
      "[2500]\ttraining's binary_logloss: 0.399544\tvalid_1's binary_logloss: 0.430606\n",
      "[2550]\ttraining's binary_logloss: 0.398839\tvalid_1's binary_logloss: 0.430407\n",
      "[2600]\ttraining's binary_logloss: 0.398076\tvalid_1's binary_logloss: 0.430134\n",
      "[2650]\ttraining's binary_logloss: 0.397365\tvalid_1's binary_logloss: 0.429912\n",
      "[2700]\ttraining's binary_logloss: 0.39669\tvalid_1's binary_logloss: 0.429727\n",
      "[2750]\ttraining's binary_logloss: 0.396024\tvalid_1's binary_logloss: 0.429601\n",
      "[2800]\ttraining's binary_logloss: 0.395389\tvalid_1's binary_logloss: 0.429453\n",
      "[2850]\ttraining's binary_logloss: 0.394734\tvalid_1's binary_logloss: 0.429266\n",
      "[2900]\ttraining's binary_logloss: 0.394047\tvalid_1's binary_logloss: 0.429058\n",
      "[2950]\ttraining's binary_logloss: 0.393395\tvalid_1's binary_logloss: 0.428869\n",
      "[3000]\ttraining's binary_logloss: 0.39276\tvalid_1's binary_logloss: 0.42873\n",
      "[3050]\ttraining's binary_logloss: 0.392183\tvalid_1's binary_logloss: 0.428582\n",
      "[3100]\ttraining's binary_logloss: 0.391489\tvalid_1's binary_logloss: 0.428389\n",
      "[3150]\ttraining's binary_logloss: 0.390804\tvalid_1's binary_logloss: 0.42817\n",
      "[3200]\ttraining's binary_logloss: 0.390281\tvalid_1's binary_logloss: 0.428081\n",
      "[3250]\ttraining's binary_logloss: 0.389669\tvalid_1's binary_logloss: 0.427947\n",
      "[3300]\ttraining's binary_logloss: 0.389075\tvalid_1's binary_logloss: 0.427808\n",
      "[3350]\ttraining's binary_logloss: 0.388542\tvalid_1's binary_logloss: 0.427708\n",
      "[3400]\ttraining's binary_logloss: 0.387954\tvalid_1's binary_logloss: 0.427569\n",
      "[3450]\ttraining's binary_logloss: 0.387381\tvalid_1's binary_logloss: 0.427423\n",
      "[3500]\ttraining's binary_logloss: 0.386814\tvalid_1's binary_logloss: 0.427279\n",
      "[3550]\ttraining's binary_logloss: 0.386275\tvalid_1's binary_logloss: 0.427187\n",
      "[3600]\ttraining's binary_logloss: 0.385741\tvalid_1's binary_logloss: 0.427083\n",
      "[3650]\ttraining's binary_logloss: 0.385162\tvalid_1's binary_logloss: 0.426956\n",
      "[3700]\ttraining's binary_logloss: 0.384609\tvalid_1's binary_logloss: 0.42681\n",
      "[3750]\ttraining's binary_logloss: 0.38408\tvalid_1's binary_logloss: 0.426703\n",
      "[3800]\ttraining's binary_logloss: 0.383546\tvalid_1's binary_logloss: 0.426609\n",
      "[3850]\ttraining's binary_logloss: 0.383006\tvalid_1's binary_logloss: 0.426498\n",
      "[3900]\ttraining's binary_logloss: 0.382472\tvalid_1's binary_logloss: 0.426375\n",
      "[3950]\ttraining's binary_logloss: 0.381956\tvalid_1's binary_logloss: 0.426276\n",
      "[4000]\ttraining's binary_logloss: 0.381464\tvalid_1's binary_logloss: 0.426218\n",
      "[4050]\ttraining's binary_logloss: 0.380961\tvalid_1's binary_logloss: 0.426135\n",
      "[4100]\ttraining's binary_logloss: 0.380469\tvalid_1's binary_logloss: 0.426065\n",
      "[4150]\ttraining's binary_logloss: 0.379969\tvalid_1's binary_logloss: 0.425964\n",
      "[4200]\ttraining's binary_logloss: 0.379485\tvalid_1's binary_logloss: 0.425877\n",
      "[4250]\ttraining's binary_logloss: 0.378972\tvalid_1's binary_logloss: 0.425773\n",
      "[4300]\ttraining's binary_logloss: 0.378512\tvalid_1's binary_logloss: 0.42571\n",
      "[4350]\ttraining's binary_logloss: 0.378029\tvalid_1's binary_logloss: 0.42563\n",
      "[4400]\ttraining's binary_logloss: 0.377553\tvalid_1's binary_logloss: 0.425538\n",
      "[4450]\ttraining's binary_logloss: 0.377053\tvalid_1's binary_logloss: 0.425455\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4500]\ttraining's binary_logloss: 0.376578\tvalid_1's binary_logloss: 0.425384\n",
      "[4550]\ttraining's binary_logloss: 0.376118\tvalid_1's binary_logloss: 0.42532\n",
      "[4600]\ttraining's binary_logloss: 0.375648\tvalid_1's binary_logloss: 0.42525\n",
      "[4650]\ttraining's binary_logloss: 0.37517\tvalid_1's binary_logloss: 0.42519\n",
      "[4700]\ttraining's binary_logloss: 0.374712\tvalid_1's binary_logloss: 0.425115\n",
      "[4750]\ttraining's binary_logloss: 0.374279\tvalid_1's binary_logloss: 0.425065\n",
      "[4800]\ttraining's binary_logloss: 0.373844\tvalid_1's binary_logloss: 0.425007\n",
      "[4850]\ttraining's binary_logloss: 0.373394\tvalid_1's binary_logloss: 0.424957\n",
      "[4900]\ttraining's binary_logloss: 0.372972\tvalid_1's binary_logloss: 0.424913\n",
      "[4950]\ttraining's binary_logloss: 0.372514\tvalid_1's binary_logloss: 0.424835\n",
      "[5000]\ttraining's binary_logloss: 0.372114\tvalid_1's binary_logloss: 0.424783\n",
      "[5050]\ttraining's binary_logloss: 0.371753\tvalid_1's binary_logloss: 0.424753\n",
      "[5100]\ttraining's binary_logloss: 0.371304\tvalid_1's binary_logloss: 0.424669\n",
      "[5150]\ttraining's binary_logloss: 0.370894\tvalid_1's binary_logloss: 0.424609\n",
      "[5200]\ttraining's binary_logloss: 0.37045\tvalid_1's binary_logloss: 0.424549\n",
      "[5250]\ttraining's binary_logloss: 0.370036\tvalid_1's binary_logloss: 0.424497\n",
      "[5300]\ttraining's binary_logloss: 0.369631\tvalid_1's binary_logloss: 0.424457\n",
      "[5350]\ttraining's binary_logloss: 0.369216\tvalid_1's binary_logloss: 0.4244\n",
      "[5400]\ttraining's binary_logloss: 0.368814\tvalid_1's binary_logloss: 0.424358\n",
      "[5450]\ttraining's binary_logloss: 0.368382\tvalid_1's binary_logloss: 0.424302\n",
      "[5500]\ttraining's binary_logloss: 0.367997\tvalid_1's binary_logloss: 0.424259\n",
      "[5550]\ttraining's binary_logloss: 0.367599\tvalid_1's binary_logloss: 0.424222\n",
      "[5600]\ttraining's binary_logloss: 0.367227\tvalid_1's binary_logloss: 0.424194\n",
      "[5650]\ttraining's binary_logloss: 0.366839\tvalid_1's binary_logloss: 0.424163\n",
      "[5700]\ttraining's binary_logloss: 0.366451\tvalid_1's binary_logloss: 0.424124\n",
      "[5750]\ttraining's binary_logloss: 0.366081\tvalid_1's binary_logloss: 0.424096\n",
      "[5800]\ttraining's binary_logloss: 0.36568\tvalid_1's binary_logloss: 0.424059\n",
      "[5850]\ttraining's binary_logloss: 0.365314\tvalid_1's binary_logloss: 0.424049\n",
      "[5900]\ttraining's binary_logloss: 0.36491\tvalid_1's binary_logloss: 0.424019\n",
      "[5950]\ttraining's binary_logloss: 0.364537\tvalid_1's binary_logloss: 0.423995\n",
      "[6000]\ttraining's binary_logloss: 0.364191\tvalid_1's binary_logloss: 0.423986\n",
      "[6050]\ttraining's binary_logloss: 0.36384\tvalid_1's binary_logloss: 0.423985\n",
      "[6100]\ttraining's binary_logloss: 0.363503\tvalid_1's binary_logloss: 0.423974\n",
      "[6150]\ttraining's binary_logloss: 0.363157\tvalid_1's binary_logloss: 0.423962\n",
      "[6200]\ttraining's binary_logloss: 0.362789\tvalid_1's binary_logloss: 0.42393\n",
      "[6250]\ttraining's binary_logloss: 0.362445\tvalid_1's binary_logloss: 0.423911\n",
      "[6300]\ttraining's binary_logloss: 0.362109\tvalid_1's binary_logloss: 0.423909\n",
      "[6350]\ttraining's binary_logloss: 0.361741\tvalid_1's binary_logloss: 0.423882\n",
      "[6400]\ttraining's binary_logloss: 0.361357\tvalid_1's binary_logloss: 0.423856\n",
      "[6450]\ttraining's binary_logloss: 0.361012\tvalid_1's binary_logloss: 0.423849\n",
      "[6500]\ttraining's binary_logloss: 0.360683\tvalid_1's binary_logloss: 0.423845\n",
      "[6550]\ttraining's binary_logloss: 0.360369\tvalid_1's binary_logloss: 0.423825\n",
      "[6600]\ttraining's binary_logloss: 0.36002\tvalid_1's binary_logloss: 0.423812\n",
      "[6650]\ttraining's binary_logloss: 0.359673\tvalid_1's binary_logloss: 0.423788\n",
      "[6700]\ttraining's binary_logloss: 0.359349\tvalid_1's binary_logloss: 0.423776\n",
      "[6750]\ttraining's binary_logloss: 0.359048\tvalid_1's binary_logloss: 0.423784\n",
      "[6800]\ttraining's binary_logloss: 0.358753\tvalid_1's binary_logloss: 0.423789\n",
      "Early stopping, best iteration is:\n",
      "[6689]\ttraining's binary_logloss: 0.359409\tvalid_1's binary_logloss: 0.42377\n",
      "最大f1为 0.8049706413926098\n",
      "此时阈值为: 0.41700000000000015\n",
      "kflod: 4\n",
      "Training until validation scores don't improve for 150 rounds.\n",
      "[50]\ttraining's binary_logloss: 0.504574\tvalid_1's binary_logloss: 0.505587\n",
      "[100]\ttraining's binary_logloss: 0.485955\tvalid_1's binary_logloss: 0.48766\n",
      "[150]\ttraining's binary_logloss: 0.476183\tvalid_1's binary_logloss: 0.478508\n",
      "[200]\ttraining's binary_logloss: 0.46918\tvalid_1's binary_logloss: 0.472143\n",
      "[250]\ttraining's binary_logloss: 0.464167\tvalid_1's binary_logloss: 0.467759\n",
      "[300]\ttraining's binary_logloss: 0.459643\tvalid_1's binary_logloss: 0.463886\n",
      "[350]\ttraining's binary_logloss: 0.456203\tvalid_1's binary_logloss: 0.461095\n",
      "[400]\ttraining's binary_logloss: 0.453031\tvalid_1's binary_logloss: 0.458639\n",
      "[450]\ttraining's binary_logloss: 0.449933\tvalid_1's binary_logloss: 0.456175\n",
      "[500]\ttraining's binary_logloss: 0.447503\tvalid_1's binary_logloss: 0.454399\n",
      "[550]\ttraining's binary_logloss: 0.445184\tvalid_1's binary_logloss: 0.452778\n",
      "[600]\ttraining's binary_logloss: 0.442921\tvalid_1's binary_logloss: 0.451125\n",
      "[650]\ttraining's binary_logloss: 0.440764\tvalid_1's binary_logloss: 0.449645\n",
      "[700]\ttraining's binary_logloss: 0.438786\tvalid_1's binary_logloss: 0.448368\n",
      "[750]\ttraining's binary_logloss: 0.436988\tvalid_1's binary_logloss: 0.447211\n",
      "[800]\ttraining's binary_logloss: 0.435331\tvalid_1's binary_logloss: 0.446242\n",
      "[850]\ttraining's binary_logloss: 0.43371\tvalid_1's binary_logloss: 0.445306\n",
      "[900]\ttraining's binary_logloss: 0.432035\tvalid_1's binary_logloss: 0.444237\n",
      "[950]\ttraining's binary_logloss: 0.43055\tvalid_1's binary_logloss: 0.443432\n",
      "[1000]\ttraining's binary_logloss: 0.429039\tvalid_1's binary_logloss: 0.442547\n",
      "[1050]\ttraining's binary_logloss: 0.427642\tvalid_1's binary_logloss: 0.44182\n",
      "[1100]\ttraining's binary_logloss: 0.426379\tvalid_1's binary_logloss: 0.441195\n",
      "[1150]\ttraining's binary_logloss: 0.425117\tvalid_1's binary_logloss: 0.440566\n",
      "[1200]\ttraining's binary_logloss: 0.42392\tvalid_1's binary_logloss: 0.440002\n",
      "[1250]\ttraining's binary_logloss: 0.422674\tvalid_1's binary_logloss: 0.439372\n",
      "[1300]\ttraining's binary_logloss: 0.421384\tvalid_1's binary_logloss: 0.438682\n",
      "[1350]\ttraining's binary_logloss: 0.420222\tvalid_1's binary_logloss: 0.438112\n",
      "[1400]\ttraining's binary_logloss: 0.419145\tvalid_1's binary_logloss: 0.437638\n",
      "[1450]\ttraining's binary_logloss: 0.418006\tvalid_1's binary_logloss: 0.437082\n",
      "[1500]\ttraining's binary_logloss: 0.416918\tvalid_1's binary_logloss: 0.436577\n",
      "[1550]\ttraining's binary_logloss: 0.415929\tvalid_1's binary_logloss: 0.436195\n",
      "[1600]\ttraining's binary_logloss: 0.414816\tvalid_1's binary_logloss: 0.435718\n",
      "[1650]\ttraining's binary_logloss: 0.413799\tvalid_1's binary_logloss: 0.435277\n",
      "[1700]\ttraining's binary_logloss: 0.412842\tvalid_1's binary_logloss: 0.434883\n",
      "[1750]\ttraining's binary_logloss: 0.411914\tvalid_1's binary_logloss: 0.434554\n",
      "[1800]\ttraining's binary_logloss: 0.411051\tvalid_1's binary_logloss: 0.434296\n",
      "[1850]\ttraining's binary_logloss: 0.410105\tvalid_1's binary_logloss: 0.433898\n",
      "[1900]\ttraining's binary_logloss: 0.409217\tvalid_1's binary_logloss: 0.433566\n",
      "[1950]\ttraining's binary_logloss: 0.408307\tvalid_1's binary_logloss: 0.433208\n",
      "[2000]\ttraining's binary_logloss: 0.407431\tvalid_1's binary_logloss: 0.43291\n",
      "[2050]\ttraining's binary_logloss: 0.406533\tvalid_1's binary_logloss: 0.432588\n",
      "[2100]\ttraining's binary_logloss: 0.405693\tvalid_1's binary_logloss: 0.432279\n",
      "[2150]\ttraining's binary_logloss: 0.404924\tvalid_1's binary_logloss: 0.432024\n",
      "[2200]\ttraining's binary_logloss: 0.404162\tvalid_1's binary_logloss: 0.431803\n",
      "[2250]\ttraining's binary_logloss: 0.403402\tvalid_1's binary_logloss: 0.431553\n",
      "[2300]\ttraining's binary_logloss: 0.40262\tvalid_1's binary_logloss: 0.431265\n",
      "[2350]\ttraining's binary_logloss: 0.401904\tvalid_1's binary_logloss: 0.431064\n",
      "[2400]\ttraining's binary_logloss: 0.40115\tvalid_1's binary_logloss: 0.430803\n",
      "[2450]\ttraining's binary_logloss: 0.400413\tvalid_1's binary_logloss: 0.430571\n",
      "[2500]\ttraining's binary_logloss: 0.399608\tvalid_1's binary_logloss: 0.430277\n",
      "[2550]\ttraining's binary_logloss: 0.398898\tvalid_1's binary_logloss: 0.430107\n",
      "[2600]\ttraining's binary_logloss: 0.398206\tvalid_1's binary_logloss: 0.429884\n",
      "[2650]\ttraining's binary_logloss: 0.397529\tvalid_1's binary_logloss: 0.429713\n",
      "[2700]\ttraining's binary_logloss: 0.396806\tvalid_1's binary_logloss: 0.429528\n",
      "[2750]\ttraining's binary_logloss: 0.396072\tvalid_1's binary_logloss: 0.429281\n",
      "[2800]\ttraining's binary_logloss: 0.395367\tvalid_1's binary_logloss: 0.429072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2850]\ttraining's binary_logloss: 0.394704\tvalid_1's binary_logloss: 0.428912\n",
      "[2900]\ttraining's binary_logloss: 0.394007\tvalid_1's binary_logloss: 0.428724\n",
      "[2950]\ttraining's binary_logloss: 0.393354\tvalid_1's binary_logloss: 0.428532\n",
      "[3000]\ttraining's binary_logloss: 0.392732\tvalid_1's binary_logloss: 0.428369\n",
      "[3050]\ttraining's binary_logloss: 0.392103\tvalid_1's binary_logloss: 0.428215\n",
      "[3100]\ttraining's binary_logloss: 0.391476\tvalid_1's binary_logloss: 0.428072\n",
      "[3150]\ttraining's binary_logloss: 0.390826\tvalid_1's binary_logloss: 0.427904\n",
      "[3200]\ttraining's binary_logloss: 0.390187\tvalid_1's binary_logloss: 0.427697\n",
      "[3250]\ttraining's binary_logloss: 0.389573\tvalid_1's binary_logloss: 0.42756\n",
      "[3300]\ttraining's binary_logloss: 0.389034\tvalid_1's binary_logloss: 0.427438\n",
      "[3350]\ttraining's binary_logloss: 0.388515\tvalid_1's binary_logloss: 0.427358\n",
      "[3400]\ttraining's binary_logloss: 0.387929\tvalid_1's binary_logloss: 0.427205\n",
      "[3450]\ttraining's binary_logloss: 0.387373\tvalid_1's binary_logloss: 0.427088\n",
      "[3500]\ttraining's binary_logloss: 0.386738\tvalid_1's binary_logloss: 0.426907\n",
      "[3550]\ttraining's binary_logloss: 0.386188\tvalid_1's binary_logloss: 0.426795\n",
      "[3600]\ttraining's binary_logloss: 0.385652\tvalid_1's binary_logloss: 0.426709\n",
      "[3650]\ttraining's binary_logloss: 0.385104\tvalid_1's binary_logloss: 0.426616\n",
      "[3700]\ttraining's binary_logloss: 0.384579\tvalid_1's binary_logloss: 0.426511\n",
      "[3750]\ttraining's binary_logloss: 0.384098\tvalid_1's binary_logloss: 0.42642\n",
      "[3800]\ttraining's binary_logloss: 0.383567\tvalid_1's binary_logloss: 0.426292\n",
      "[3850]\ttraining's binary_logloss: 0.38307\tvalid_1's binary_logloss: 0.426215\n",
      "[3900]\ttraining's binary_logloss: 0.382573\tvalid_1's binary_logloss: 0.426124\n",
      "[3950]\ttraining's binary_logloss: 0.382069\tvalid_1's binary_logloss: 0.42604\n",
      "[4000]\ttraining's binary_logloss: 0.381609\tvalid_1's binary_logloss: 0.425965\n",
      "[4050]\ttraining's binary_logloss: 0.381152\tvalid_1's binary_logloss: 0.425892\n",
      "[4100]\ttraining's binary_logloss: 0.38065\tvalid_1's binary_logloss: 0.425789\n",
      "[4150]\ttraining's binary_logloss: 0.380154\tvalid_1's binary_logloss: 0.425734\n",
      "[4200]\ttraining's binary_logloss: 0.379613\tvalid_1's binary_logloss: 0.425633\n",
      "[4250]\ttraining's binary_logloss: 0.379076\tvalid_1's binary_logloss: 0.425522\n",
      "[4300]\ttraining's binary_logloss: 0.378566\tvalid_1's binary_logloss: 0.42545\n",
      "[4350]\ttraining's binary_logloss: 0.378091\tvalid_1's binary_logloss: 0.425367\n",
      "[4400]\ttraining's binary_logloss: 0.377604\tvalid_1's binary_logloss: 0.425278\n",
      "[4450]\ttraining's binary_logloss: 0.377133\tvalid_1's binary_logloss: 0.425214\n",
      "[4500]\ttraining's binary_logloss: 0.376704\tvalid_1's binary_logloss: 0.425154\n",
      "[4550]\ttraining's binary_logloss: 0.376224\tvalid_1's binary_logloss: 0.425078\n",
      "[4600]\ttraining's binary_logloss: 0.375767\tvalid_1's binary_logloss: 0.425003\n",
      "[4650]\ttraining's binary_logloss: 0.375321\tvalid_1's binary_logloss: 0.424955\n",
      "[4700]\ttraining's binary_logloss: 0.37483\tvalid_1's binary_logloss: 0.424867\n",
      "[4750]\ttraining's binary_logloss: 0.374427\tvalid_1's binary_logloss: 0.424813\n",
      "[4800]\ttraining's binary_logloss: 0.373957\tvalid_1's binary_logloss: 0.424759\n",
      "[4850]\ttraining's binary_logloss: 0.373547\tvalid_1's binary_logloss: 0.424706\n",
      "[4900]\ttraining's binary_logloss: 0.373122\tvalid_1's binary_logloss: 0.424666\n",
      "[4950]\ttraining's binary_logloss: 0.372712\tvalid_1's binary_logloss: 0.424614\n",
      "[5000]\ttraining's binary_logloss: 0.372307\tvalid_1's binary_logloss: 0.424582\n",
      "[5050]\ttraining's binary_logloss: 0.371951\tvalid_1's binary_logloss: 0.424562\n",
      "[5100]\ttraining's binary_logloss: 0.371549\tvalid_1's binary_logloss: 0.424519\n",
      "[5150]\ttraining's binary_logloss: 0.371114\tvalid_1's binary_logloss: 0.424469\n",
      "[5200]\ttraining's binary_logloss: 0.3707\tvalid_1's binary_logloss: 0.424415\n",
      "[5250]\ttraining's binary_logloss: 0.370285\tvalid_1's binary_logloss: 0.424369\n",
      "[5300]\ttraining's binary_logloss: 0.369871\tvalid_1's binary_logloss: 0.424334\n",
      "[5350]\ttraining's binary_logloss: 0.369466\tvalid_1's binary_logloss: 0.424295\n",
      "[5400]\ttraining's binary_logloss: 0.369094\tvalid_1's binary_logloss: 0.424275\n",
      "[5450]\ttraining's binary_logloss: 0.368707\tvalid_1's binary_logloss: 0.424244\n",
      "[5500]\ttraining's binary_logloss: 0.368343\tvalid_1's binary_logloss: 0.424224\n",
      "[5550]\ttraining's binary_logloss: 0.367963\tvalid_1's binary_logloss: 0.424193\n",
      "[5600]\ttraining's binary_logloss: 0.367569\tvalid_1's binary_logloss: 0.424142\n",
      "[5650]\ttraining's binary_logloss: 0.367198\tvalid_1's binary_logloss: 0.424103\n",
      "[5700]\ttraining's binary_logloss: 0.3668\tvalid_1's binary_logloss: 0.424048\n",
      "[5750]\ttraining's binary_logloss: 0.366399\tvalid_1's binary_logloss: 0.423994\n",
      "[5800]\ttraining's binary_logloss: 0.366001\tvalid_1's binary_logloss: 0.423947\n",
      "[5850]\ttraining's binary_logloss: 0.365592\tvalid_1's binary_logloss: 0.423907\n",
      "[5900]\ttraining's binary_logloss: 0.365206\tvalid_1's binary_logloss: 0.42387\n",
      "[5950]\ttraining's binary_logloss: 0.364866\tvalid_1's binary_logloss: 0.423862\n",
      "[6000]\ttraining's binary_logloss: 0.3645\tvalid_1's binary_logloss: 0.423834\n",
      "[6050]\ttraining's binary_logloss: 0.364154\tvalid_1's binary_logloss: 0.423805\n",
      "[6100]\ttraining's binary_logloss: 0.363786\tvalid_1's binary_logloss: 0.423773\n",
      "[6150]\ttraining's binary_logloss: 0.363428\tvalid_1's binary_logloss: 0.423746\n",
      "[6200]\ttraining's binary_logloss: 0.363074\tvalid_1's binary_logloss: 0.423729\n",
      "[6250]\ttraining's binary_logloss: 0.362715\tvalid_1's binary_logloss: 0.423696\n",
      "[6300]\ttraining's binary_logloss: 0.362332\tvalid_1's binary_logloss: 0.42365\n",
      "[6350]\ttraining's binary_logloss: 0.361977\tvalid_1's binary_logloss: 0.423633\n",
      "[6400]\ttraining's binary_logloss: 0.361644\tvalid_1's binary_logloss: 0.423628\n",
      "[6450]\ttraining's binary_logloss: 0.361337\tvalid_1's binary_logloss: 0.42363\n",
      "[6500]\ttraining's binary_logloss: 0.360968\tvalid_1's binary_logloss: 0.423609\n",
      "[6550]\ttraining's binary_logloss: 0.360625\tvalid_1's binary_logloss: 0.423597\n",
      "[6600]\ttraining's binary_logloss: 0.360286\tvalid_1's binary_logloss: 0.423558\n",
      "[6650]\ttraining's binary_logloss: 0.359967\tvalid_1's binary_logloss: 0.423548\n",
      "[6700]\ttraining's binary_logloss: 0.359605\tvalid_1's binary_logloss: 0.423534\n",
      "[6750]\ttraining's binary_logloss: 0.359285\tvalid_1's binary_logloss: 0.423534\n",
      "[6800]\ttraining's binary_logloss: 0.358973\tvalid_1's binary_logloss: 0.423524\n",
      "[6850]\ttraining's binary_logloss: 0.35866\tvalid_1's binary_logloss: 0.423538\n",
      "[6900]\ttraining's binary_logloss: 0.358313\tvalid_1's binary_logloss: 0.423518\n",
      "[6950]\ttraining's binary_logloss: 0.358012\tvalid_1's binary_logloss: 0.423522\n",
      "[7000]\ttraining's binary_logloss: 0.357733\tvalid_1's binary_logloss: 0.423535\n",
      "[7050]\ttraining's binary_logloss: 0.357463\tvalid_1's binary_logloss: 0.423543\n",
      "Early stopping, best iteration is:\n",
      "[6930]\ttraining's binary_logloss: 0.358124\tvalid_1's binary_logloss: 0.423513\n",
      "最大f1为 0.8048183502919682\n",
      "此时阈值为: 0.43000000000000016\n",
      "avg_test_f1: 0.806257552005901\n"
     ]
    }
   ],
   "source": [
    "def find_best_thr(predict,vali_label):\n",
    "    max = 0.0\n",
    "    max_i =0.0\n",
    "    predict = pd.DataFrame(predict)\n",
    "    predict = predict[1]\n",
    "    predict = pd.DataFrame(predict)\n",
    "    for i in np.arange(0.25, 0.4500, 0.001):\n",
    "        f1 = f1_score(vali_label, predict[1].map(lambda x: 0 if x < i else 1))\n",
    "        if (f1 > max):\n",
    "            max = f1_score(vali_label, predict[1].map(lambda x: 0 if x <= i else 1))\n",
    "            max_i = i\n",
    "    print('最大f1为', max)\n",
    "    print('此时阈值为:', max_i)\n",
    "\n",
    "    return max,max_i\n",
    "from  sklearn.model_selection import StratifiedKFold\n",
    "# train_X_data = pd.concat([train_X_data,vali_X_data])\n",
    "# train_Y_data = pd.concat([train_Y_data,vali_label])\n",
    "# train_X_data.reset_index()\n",
    "# train_Y_data.reset_index()\n",
    "skf = StratifiedKFold(n_splits=5,shuffle=True,random_state=2018)\n",
    "submit = []\n",
    "vali_f1 = []\n",
    "for k,(train_in,test_in) in enumerate(skf.split(train_X_data,train_Y_data)):\n",
    "    print('kflod:',k)\n",
    "    train_X,test_X,train_y,test_y  = train_X_data.loc[train_in],train_X_data.loc[test_in],train_Y_data.loc[train_in],train_Y_data.loc[test_in]\n",
    "    \n",
    "    clf = lgb.LGBMClassifier(\n",
    "    boosting_type='gbdt', subsample=1, colsample_bytree=1,\n",
    "    max_depth=-1, n_estimators=10000, objective='binary',min_child_weight = 10,\n",
    "    subsample_freq=1, num_leaves=127, reg_alpha=0,reg_lambda = 1.3,\n",
    "    random_state=2018, n_jobs=-1, learning_rate=0.1)\n",
    "\n",
    "    clf.fit(train_X, train_y,eval_set=[(train_X,train_y),(test_X,test_y)], eval_metric='logloss',verbose = 50, early_stopping_rounds=150)\n",
    "    \n",
    "    predict = clf.predict_proba(vali_X_data,num_iteration=clf.best_iteration_)\n",
    "    best_f1,best_thr = find_best_thr(predict,vali_label)\n",
    "    vali_f1.append(best_f1)\n",
    "    \n",
    "    test_pred = pd.DataFrame(clf.predict_proba(test_X_data,num_iteration=clf.best_iteration_))[1]\n",
    "    submit.append(test_pred)\n",
    "\n",
    "for i in range(0,4):\n",
    "    submit[0] += submit[i]\n",
    "    vali_f1[0] += vali_f1[i]\n",
    "avg_vali_f1 = vali_f1[0]/5\n",
    "avg_test_pred = submit[0]/5\n",
    "print('avg_test_f1:',avg_vali_f1)\n",
    "avg_test_pred.to_csv('avg_test_pred.csv',index=False,encoding='utf-8',header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
