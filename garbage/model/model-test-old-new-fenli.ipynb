{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "train= pd.read_csv('E:/competionfile/oppo/data/train_data_10_8_1.csv')\n",
    "test = pd.read_csv('E:/competionfile/oppo/data/test_data_10_8_1.csv')\n",
    "co_list = [ 'prefix', 'query_prediction', 'title', 'tag']\n",
    "train_data = train.drop(co_list , axis = 1 )\n",
    "test_data = test.drop(co_list, axis = 1 )\n",
    "train_X_data = train_data.drop(['label'],axis=1)\n",
    "train_Y_data = train_data['label']\n",
    "test_X_data = test_data.drop(['label'],axis=1)\n",
    "vali_data = test_data['label']\n",
    "pd.set_option('display.max_columns',55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['prefix_count', 'title_count', 'tag_count', 'prefix_tag_count',\n",
       "       'prefix_title_count', 'title_tag_count', 'prefix_title_tag_count',\n",
       "       'prefix_pred_0', 'prefix_pred_1', 'query_prediction_pred_0',\n",
       "       'query_prediction_pred_1', 'title_pred_0', 'title_pred_1', 'title_ctr',\n",
       "       'prefix_ctr', 'tag_ctr', 'prefix_tag_ctr', 'title_tag_ctr',\n",
       "       'prefix_title_ctr', 'smi_pre_ti', 'prefix_len', 'title_len'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_X_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Dataset' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-e2751fbd6116>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# train_X_data[ train_X_data['prefix_count']  <=2 ]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtest_X_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'prefix_count'\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'Dataset' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "# train_X_data[ train_X_data['prefix_count']  <=2 ]\n",
    "test_X_data[test_data['prefix_count']  < 2 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X_data['prefix_ctr'] = train_X_data.apply( lambda x : x['prefix_ctr'] if x['prefix_count'] > 2 else 0.50 , axis =1   )\n",
    "# train_X_data['prefix_title_ctr'] = train_X_data.apply( lambda x : x['prefix_title_ctr'] if x['prefix_count'] > 2 else x['title_ctr'] , axis =1  )\n",
    "# train_X_data['prefix_tag_ctr'] = train_X_data.apply( lambda x : x['prefix_tag_ctr'] if x['prefix_count'] > 2 else x['tag_ctr'] , axis =1 )\n",
    "\n",
    "# train_X_data[ ['prefix_ctr','prefix_title_ctr','prefix_tag_ctr'] ].to_csv('E:/competionfile/oppo/data/model-test-old-new-fenli/3ctr.csv')\n",
    "\n",
    "\n",
    "test_X_data['prefix_ctr'] = test_X_data.apply( lambda x : x['prefix_ctr'] if x['prefix_count'] > 2 else 0.50 , axis =1   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Users\\tkhoon\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xgb_predict\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0  0.79468756 0.89428280 0.84154872     31414\n",
      "          1  0.77327963 0.60947000 0.68167183     18585\n",
      "\n",
      "avg / total  0.78673007 0.78841577 0.78212129     49999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#用xgb跑一下\n",
    "from pylab import mpl\n",
    "from matplotlib import pyplot as plt\n",
    "mpl.rcParams['font.sans-serif'] = ['SimHei'] \n",
    "def plot_feature_importance(df,title):\n",
    "        \"\"\"\n",
    "    Plot importances returned by a model. This can work with any measure of\n",
    "    feature importance provided that higher importance is better. \n",
    "    \n",
    "    Args:\n",
    "        df (dataframe): feature importances. Must have the features in a column\n",
    "        called `features` and the importances in a column called `importance\n",
    "        \n",
    "    Returns:\n",
    "        shows a plot of the 15 most importance features\n",
    "        \n",
    "        df (dataframe): feature importances sorted by importance (highest to lowest) \n",
    "        with a column for normalized importance\n",
    "        \"\"\"\n",
    "        df = df.sort_values('importance',ascending = False,).reset_index()\n",
    "        df['importance_normalized'] = df['importance']/df['importance'].sum()\n",
    "        \n",
    "        plt.figure(figsize=(10,6))\n",
    "        ax = plt.subplot()\n",
    "        \n",
    "        #取前15个feature\n",
    "        ax.barh(list(reversed(list(df.index[:]))), df['importance_normalized'], align = 'center', edgecolor = 'k')\n",
    "        \n",
    "        ax.set_yticks(list(reversed(list(df.index[:]))))\n",
    "        ax.set_yticklabels(df['feature'])\n",
    "        \n",
    "        plt.xlabel('Normalized Importance')\n",
    "        plt.title(title)\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        return df\n",
    "import xgboost as xgb\n",
    "xgb =  xgb.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
    "       max_depth=9, min_child_weight=5, missing=None, n_estimators=10,\n",
    "       n_jobs=1, nthread=4, objective='binary:logistic', random_state=0,\n",
    "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=27, silent=0,\n",
    "       subsample=0.8)\n",
    "model = xgb.fit(train_X_data,train_Y_data,eval_metric='auc')\n",
    "feature_importance_values = model.feature_importances_\n",
    "features = list(train_X_data.columns)\n",
    "\n",
    "xgb_feature_importances = pd.DataFrame({'feature':features,'importance':feature_importance_values})\n",
    "\n",
    "plot_feature_importance(xgb_feature_importances,'xgb_feature_importances')\n",
    "from sklearn.metrics import classification_report\n",
    "xgb_predict_label = model.predict(test_X_data)\n",
    "print('xgb_predict') \n",
    "print(classification_report(vali_data,xgb_predict_label,digits=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's l1: 0.373\tvalid_0's myFeval: 0.698494\n",
      "[2]\tvalid_0's l1: 0.37429\tvalid_0's myFeval: 0.698494\n",
      "[3]\tvalid_0's l1: 0.375577\tvalid_0's myFeval: 0.698326\n",
      "[4]\tvalid_0's l1: 0.376861\tvalid_0's myFeval: 0.698072\n",
      "[5]\tvalid_0's l1: 0.378126\tvalid_0's myFeval: 0.698154\n",
      "[6]\tvalid_0's l1: 0.379394\tvalid_0's myFeval: 0.698242\n",
      "[7]\tvalid_0's l1: 0.380706\tvalid_0's myFeval: 0.691952\n",
      "[8]\tvalid_0's l1: 0.381963\tvalid_0's myFeval: 0.691371\n",
      "[9]\tvalid_0's l1: 0.383293\tvalid_0's myFeval: 0.690575\n",
      "[10]\tvalid_0's l1: 0.384552\tvalid_0's myFeval: 0.690627\n",
      "[11]\tvalid_0's l1: 0.385802\tvalid_0's myFeval: 0.690291\n",
      "[12]\tvalid_0's l1: 0.387053\tvalid_0's myFeval: 0.690257\n",
      "[13]\tvalid_0's l1: 0.388378\tvalid_0's myFeval: 0.689955\n",
      "[14]\tvalid_0's l1: 0.389579\tvalid_0's myFeval: 0.689145\n",
      "[15]\tvalid_0's l1: 0.390896\tvalid_0's myFeval: 0.682022\n",
      "[16]\tvalid_0's l1: 0.392143\tvalid_0's myFeval: 0.689949\n",
      "[17]\tvalid_0's l1: 0.39334\tvalid_0's myFeval: 0.688895\n",
      "[18]\tvalid_0's l1: 0.394654\tvalid_0's myFeval: 0.680431\n",
      "[19]\tvalid_0's l1: 0.39597\tvalid_0's myFeval: 0.681712\n",
      "[20]\tvalid_0's l1: 0.397153\tvalid_0's myFeval: 0.680431\n",
      "xgb_predict\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0  0.79670694 0.87951232 0.83606433     31414\n",
      "          1  0.75293734 0.62066182 0.68043061     18585\n",
      "\n",
      "avg / total  0.78043745 0.78329567 0.77821412     49999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "import lightgbm as lgb\n",
    "params = {'metric': 'l1',\n",
    "          'boosting_type': 'gbdt',\n",
    "          'max_depth':8,\n",
    "          'num_leaves':300,\n",
    "          'num_threads':4,\n",
    "          'objective':'binary',\n",
    "          'bagging_fraction':0.5,\n",
    "          # 'bagging_freq':1,\n",
    "          'learning_rate' : 0.002,\n",
    "          'min_data_in_leaf' : 5,\n",
    "#           'min_data_per_group' : 1,\n",
    "          # 'weight' : ''\n",
    "          }\n",
    "\n",
    "def myFeval(   preds, train):\n",
    "#     aa = pd.Series(train.get_label()).map( lambda x: 1 if x >= 0.5 else 0 )\n",
    "#     print()\n",
    "    score = f1_score(train.get_label(),pd.Series(preds).map( lambda x: 1 if x >= 0.5 else 0 ))\n",
    "    return 'myFeval',score,False\n",
    "train_data = lgb.Dataset( train_X_data , train_Y_data  ,free_raw_data=False ,  )\n",
    "test_data = lgb.Dataset( test_X_data , vali_data , reference= train_data )\n",
    "gbm = lgb.train(params,train_data,valid_sets=test_data,num_boost_round=20,feval = myFeval )\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "xgb_predict_label = gbm.predict(test_X_data )\n",
    "xgb_predict_label = pd.Series( xgb_predict_label  ).map(lambda x : 1 if x>= 0.5 else 0)\n",
    "print('xgb_predict') \n",
    "print(classification_report(vali_data,xgb_predict_label,digits=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          0\n",
       "1          0\n",
       "2          1\n",
       "3          1\n",
       "4          0\n",
       "5          1\n",
       "6          0\n",
       "7          0\n",
       "8          1\n",
       "9          0\n",
       "10         0\n",
       "11         1\n",
       "12         0\n",
       "13         0\n",
       "14         0\n",
       "15         0\n",
       "16         0\n",
       "17         0\n",
       "18         0\n",
       "19         0\n",
       "20         0\n",
       "21         0\n",
       "22         1\n",
       "23         1\n",
       "24         0\n",
       "25         0\n",
       "26         1\n",
       "27         0\n",
       "28         1\n",
       "29         1\n",
       "          ..\n",
       "1999964    0\n",
       "1999965    0\n",
       "1999966    0\n",
       "1999967    0\n",
       "1999968    0\n",
       "1999969    0\n",
       "1999970    0\n",
       "1999971    0\n",
       "1999972    1\n",
       "1999973    1\n",
       "1999974    1\n",
       "1999975    1\n",
       "1999976    0\n",
       "1999977    1\n",
       "1999978    1\n",
       "1999979    0\n",
       "1999980    0\n",
       "1999981    0\n",
       "1999982    1\n",
       "1999983    0\n",
       "1999984    0\n",
       "1999985    0\n",
       "1999986    1\n",
       "1999987    0\n",
       "1999988    0\n",
       "1999989    1\n",
       "1999990    1\n",
       "1999991    1\n",
       "1999992    0\n",
       "1999993    1\n",
       "Name: label, Length: 1999994, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_Y_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
